{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import default_rng\n",
    "rng = default_rng()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Paramètres : \n",
    "\n",
    "S0 = 40  # Prix initial\n",
    "K = 40  # Prix d'exercice\n",
    "T = 1    # Maturité en années\n",
    "r = 0.06 # Taux d'intérêt sans risque\n",
    "sigma = 0.4 # Volatilité\n",
    "N = 10  # Nombre de pas\n",
    "dt = T / N  # Intervalle de temps\n",
    "M = int(2**10) # Nombre de chemins MC\n",
    "\n",
    "lambda_ = 0.0005 # paramètre de régularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_black_scholes_paths(size_path, size_sample): \n",
    "    dt = T/size_path\n",
    "    gaussien_inc = np.sqrt(dt)*rng.standard_normal(size=(size_path, size_sample))\n",
    "    sample = np.zeros(shape=(size_path+1, size_sample))\n",
    "    sample[0] = S0\n",
    "    for n in range(1, size_path+1):\n",
    "        sample[n] = sample[n-1] * np.exp((r - 0.5 * sigma**2)*dt + sigma*gaussien_inc[n-1])\n",
    "    return sample\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "g = lambda x : np.maximum(K-x,0) # payoff function\n",
    "\n",
    "R = lambda x : x-x*np.log(x) # Regularization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_price = 5.31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_samples = generate_black_scholes_paths(N-1,M).T\n",
    "data_train = generate_black_scholes_paths(N-1,M).T\n",
    "data_test = generate_black_scholes_paths(N-1,M).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "creterio  = nn.MSELoss()\n",
    "\n",
    "\n",
    "def Phi_NN() :\n",
    "\n",
    "    class NeuralNetwork(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.linear_relu_stack = nn.Sequential(\n",
    "                nn.Linear(1, 21),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(21, 21),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(21, 21),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(21, 21),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(21, 21),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(21, 21),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(21, 1),\n",
    "                nn.LeakyReLU(negative_slope=0.01)\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            out = self.linear_relu_stack(x)\n",
    "            payoff = torch.max(K - x, torch.tensor(0.0))\n",
    "            #payoff = (K-x)*torch.sigmoid(K - x)\n",
    "            return out  +payoff\n",
    "        \n",
    "\n",
    "    # Define the optimizers and the networks : \n",
    "\n",
    "    Phi_functions = [NeuralNetwork().to(device) for n in range(1,N)]\n",
    "\n",
    "    optimizers = [optim.Adam(Phi_functions[n-1].parameters(), lr=0.0001) for n in range(1,N)]\n",
    "\n",
    "    return Phi_functions,optimizers\n",
    "\n",
    "\n",
    "######################## \n",
    "\n",
    "def payoff_phi(n, x): \n",
    "    return np.exp(-r*n*T/N) * np.maximum(K-x, 0)\n",
    "\n",
    "\n",
    "def calculate_price(Phi_functions,data_train):\n",
    "\n",
    "    \n",
    "    payoffs = np.empty_like(data_train)\n",
    "    for n in range(0, N):\n",
    "        payoffs[:,n] = payoff_phi(n, data_train[:,n])\n",
    "    \n",
    "    payoff_opt = payoffs[:,-1].copy() # Payoffs optimaux à l'instant t = N\n",
    "\n",
    "    for n in range(N-1,0,-1):\n",
    "\n",
    "        xx = torch.tensor(data_train[:, n], dtype=torch.float32, device=device).reshape(-1, 1)\n",
    "        with torch.no_grad():\n",
    "                continuation_function = Phi_functions[n-1](xx).cpu().numpy().flatten()\n",
    "\n",
    "        stop_at_n = payoffs[:,n] >= continuation_function\n",
    "        payoff_opt[stop_at_n] = payoffs[stop_at_n,n].copy() # Payoffs optimaux à l'instant t = n\n",
    "\n",
    "\n",
    "    payoff_opt.mean()\n",
    "    \n",
    "\n",
    "    return payoff_opt.mean()\n",
    "\n",
    "\n",
    "\n",
    "#############################\n",
    "\n",
    "\n",
    "def train_evaluate(n_iteration,lambda_,Phi_functions,optimizers):\n",
    "\n",
    "\n",
    "    Losses = []\n",
    "    pi_values = np.ones_like(data_train)\n",
    "    P = []\n",
    "\n",
    "    for n in range(n_iteration): \n",
    "\n",
    "        S_samples = generate_black_scholes_paths(N-1,M).T\n",
    "        #S_samples = data_train.copy()\n",
    "        V_values = np.zeros_like(S_samples)\n",
    "        V_values[:,-1] = g(S_samples[:,-1])\n",
    "\n",
    "\n",
    "        print(f'{n+1} Iteration ...')\n",
    "        \n",
    "\n",
    "        total_loss = 0\n",
    "        for l in range(N-2,-1,-1):\n",
    "            \n",
    "        \n",
    "            #Calculate the TD-error :\n",
    "            \n",
    "            ## construct target vector\n",
    "            X = S_samples[:,l]\n",
    "            Y = g(S_samples[:,l])*pi_values[:,l]*dt + lambda_*R(pi_values[:,l])*dt+np.exp(-r*dt)*V_values[:,l+1]*(1-pi_values[:,l]*dt)\n",
    "\n",
    "            xx = torch.tensor(X, dtype=torch.float32, device=device).reshape(-1, 1)\n",
    "            yy = torch.tensor(Y, dtype=torch.float32, device=device)\n",
    "\n",
    "            #print(f\"Start training V_{l} ...\")\n",
    "            # entrainement \"one step Gadient descent\" :\n",
    "            prediction = Phi_functions[l](xx)\n",
    "            loss = creterio(prediction, yy.reshape(-1, 1))\n",
    "            optimizers[l].zero_grad()\n",
    "            loss.backward()\n",
    "            optimizers[l].step()\n",
    "            #print(f\"model trained ! ...\")\n",
    "            total_loss+=loss\n",
    "\n",
    "            # Calculate the new V using the updated parameters \n",
    "            with torch.no_grad():\n",
    "                new_y =Phi_functions[l](xx).cpu().numpy().flatten()\n",
    "            \n",
    "            V_values[:,l] = new_y\n",
    "        \n",
    "\n",
    "        pi_values = np.ones_like(S_samples)\n",
    "        pi_values[:,:-1] = np.exp(np.clip(-(V_values[:,:-1]-g(S_samples[:,:-1])) / lambda_, -5, 5))\n",
    "        \n",
    "        if n%1 == 0 :\n",
    "            data_test = generate_black_scholes_paths(N-1,M).T\n",
    "            price,_ = calculate_price(Phi_functions,data_test)\n",
    "            relative_error = np.abs(optimal_price-price)/price\n",
    "\n",
    "        \n",
    "        P.append(relative_error)\n",
    "        print(f\"Epochs {n+1} finished !\")\n",
    "        print(f\"TOTAL LOSS : {total_loss/N}\")\n",
    "        Losses.append((total_loss/N).detach().cpu().numpy())\n",
    "\n",
    "\n",
    "    return P\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "creterio  = nn.MSELoss()\n",
    "\n",
    "\n",
    "def Phi_NN() :\n",
    "\n",
    "    class NeuralNetwork(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.linear_relu_stack = nn.Sequential(\n",
    "                nn.Linear(1, 21),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(21, 21),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(21, 21),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(21, 21),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(21, 21),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(21, 21),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(21, 1),\n",
    "                nn.LeakyReLU(negative_slope=0.01)\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            out = self.linear_relu_stack(x)\n",
    "            payoff = torch.max(K - x, torch.tensor(0.0))\n",
    "            #payoff = (K-x)*torch.sigmoid(K - x)\n",
    "            return out  +payoff\n",
    "        \n",
    "\n",
    "    # Define the optimizers and the networks : \n",
    "\n",
    "    Phi_functions = [NeuralNetwork().to(device) for n in range(1,N)]\n",
    "\n",
    "    optimizers = [optim.Adam(Phi_functions[n-1].parameters(), lr=0.0001) for n in range(1,N)]\n",
    "\n",
    "    return Phi_functions,optimizers\n",
    "\n",
    "\n",
    "######################## \n",
    "\n",
    "def payoff_phi(n, x): \n",
    "    return np.exp(-r*n*T/N) * np.maximum(K-x, 0)\n",
    "\n",
    "\n",
    "def calculate_price(Phi_functions,data_train):\n",
    "\n",
    "    \n",
    "    payoffs = np.empty_like(data_train)\n",
    "    for n in range(0, N):\n",
    "        payoffs[:,n] = payoff_phi(n, data_train[:,n])\n",
    "    \n",
    "    payoff_opt = payoffs[:,-1].copy() # Payoffs optimaux à l'instant t = N\n",
    "\n",
    "    for n in range(N-1,0,-1):\n",
    "\n",
    "        xx = torch.tensor(data_train[:, n], dtype=torch.float32, device=device).reshape(-1, 1)\n",
    "        with torch.no_grad():\n",
    "                continuation_function = Phi_functions[n-1](xx).cpu().numpy().flatten()\n",
    "\n",
    "        stop_at_n = payoffs[:,n] >= continuation_function\n",
    "        payoff_opt[stop_at_n] = payoffs[stop_at_n,n].copy() # Payoffs optimaux à l'instant t = n\n",
    "\n",
    "\n",
    "    payoff_opt.mean()\n",
    "    \n",
    "\n",
    "    return payoff_opt.mean(),np.array(payoff_opt)\n",
    "\n",
    "\n",
    "\n",
    "#############################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_values = [100,10,1,0.1]\n",
    "n_iteration = 1000\n",
    "\n",
    "data_test = generate_black_scholes_paths(N-1,2**18).T\n",
    "data_train = generate_black_scholes_paths(N-1,2**10).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Iteration ...\n",
      "Epochs 1 finished !\n",
      "TOTAL LOSS : 106.43953704833984\n",
      "2 Iteration ...\n",
      "Epochs 2 finished !\n",
      "TOTAL LOSS : 106.42756652832031\n",
      "3 Iteration ...\n",
      "Epochs 3 finished !\n",
      "TOTAL LOSS : 106.41301727294922\n",
      "4 Iteration ...\n",
      "Epochs 4 finished !\n",
      "TOTAL LOSS : 106.39808654785156\n",
      "5 Iteration ...\n",
      "Epochs 5 finished !\n",
      "TOTAL LOSS : 106.38282775878906\n",
      "6 Iteration ...\n",
      "Epochs 6 finished !\n",
      "TOTAL LOSS : 106.3676528930664\n",
      "7 Iteration ...\n",
      "Epochs 7 finished !\n",
      "TOTAL LOSS : 106.35272216796875\n",
      "8 Iteration ...\n",
      "Epochs 8 finished !\n",
      "TOTAL LOSS : 106.33778381347656\n",
      "9 Iteration ...\n",
      "Epochs 9 finished !\n",
      "TOTAL LOSS : 106.32274627685547\n",
      "10 Iteration ...\n",
      "Epochs 10 finished !\n",
      "TOTAL LOSS : 106.30769348144531\n",
      "11 Iteration ...\n",
      "Epochs 11 finished !\n",
      "TOTAL LOSS : 106.2928237915039\n",
      "12 Iteration ...\n",
      "Epochs 12 finished !\n",
      "TOTAL LOSS : 106.27815246582031\n",
      "13 Iteration ...\n",
      "Epochs 13 finished !\n",
      "TOTAL LOSS : 106.26457977294922\n",
      "14 Iteration ...\n",
      "Epochs 14 finished !\n",
      "TOTAL LOSS : 106.252197265625\n",
      "15 Iteration ...\n",
      "Epochs 15 finished !\n",
      "TOTAL LOSS : 106.23992919921875\n",
      "16 Iteration ...\n",
      "Epochs 16 finished !\n",
      "TOTAL LOSS : 106.2278060913086\n",
      "17 Iteration ...\n",
      "Epochs 17 finished !\n",
      "TOTAL LOSS : 106.21556854248047\n",
      "18 Iteration ...\n",
      "Epochs 18 finished !\n",
      "TOTAL LOSS : 106.20352935791016\n",
      "19 Iteration ...\n",
      "Epochs 19 finished !\n",
      "TOTAL LOSS : 106.19144439697266\n",
      "20 Iteration ...\n",
      "Epochs 20 finished !\n",
      "TOTAL LOSS : 106.17872619628906\n",
      "21 Iteration ...\n",
      "Epochs 21 finished !\n",
      "TOTAL LOSS : 106.16644287109375\n",
      "22 Iteration ...\n",
      "Epochs 22 finished !\n",
      "TOTAL LOSS : 106.1539535522461\n",
      "23 Iteration ...\n",
      "Epochs 23 finished !\n",
      "TOTAL LOSS : 106.1409912109375\n",
      "24 Iteration ...\n",
      "Epochs 24 finished !\n",
      "TOTAL LOSS : 106.12767791748047\n",
      "25 Iteration ...\n",
      "Epochs 25 finished !\n",
      "TOTAL LOSS : 106.11407470703125\n",
      "26 Iteration ...\n",
      "Epochs 26 finished !\n",
      "TOTAL LOSS : 106.10021209716797\n",
      "27 Iteration ...\n",
      "Epochs 27 finished !\n",
      "TOTAL LOSS : 106.08747863769531\n",
      "28 Iteration ...\n",
      "Epochs 28 finished !\n",
      "TOTAL LOSS : 106.07611083984375\n",
      "29 Iteration ...\n",
      "Epochs 29 finished !\n",
      "TOTAL LOSS : 106.06477355957031\n",
      "30 Iteration ...\n",
      "Epochs 30 finished !\n",
      "TOTAL LOSS : 106.05348205566406\n",
      "31 Iteration ...\n",
      "Epochs 31 finished !\n",
      "TOTAL LOSS : 106.04219055175781\n",
      "32 Iteration ...\n",
      "Epochs 32 finished !\n",
      "TOTAL LOSS : 106.03076171875\n",
      "33 Iteration ...\n",
      "Epochs 33 finished !\n",
      "TOTAL LOSS : 106.01888275146484\n",
      "34 Iteration ...\n",
      "Epochs 34 finished !\n",
      "TOTAL LOSS : 106.00682830810547\n",
      "35 Iteration ...\n",
      "Epochs 35 finished !\n",
      "TOTAL LOSS : 105.9942626953125\n",
      "36 Iteration ...\n",
      "Epochs 36 finished !\n",
      "TOTAL LOSS : 105.98091125488281\n",
      "37 Iteration ...\n",
      "Epochs 37 finished !\n",
      "TOTAL LOSS : 105.96721649169922\n",
      "38 Iteration ...\n",
      "Epochs 38 finished !\n",
      "TOTAL LOSS : 105.953125\n",
      "39 Iteration ...\n",
      "Epochs 39 finished !\n",
      "TOTAL LOSS : 105.9388427734375\n",
      "40 Iteration ...\n",
      "Epochs 40 finished !\n",
      "TOTAL LOSS : 105.92431640625\n",
      "41 Iteration ...\n",
      "Epochs 41 finished !\n",
      "TOTAL LOSS : 105.90959930419922\n",
      "42 Iteration ...\n",
      "Epochs 42 finished !\n",
      "TOTAL LOSS : 105.89461517333984\n",
      "43 Iteration ...\n",
      "Epochs 43 finished !\n",
      "TOTAL LOSS : 105.87935638427734\n",
      "44 Iteration ...\n",
      "Epochs 44 finished !\n",
      "TOTAL LOSS : 105.86397552490234\n",
      "45 Iteration ...\n",
      "Epochs 45 finished !\n",
      "TOTAL LOSS : 105.84862518310547\n",
      "46 Iteration ...\n",
      "Epochs 46 finished !\n",
      "TOTAL LOSS : 105.83324432373047\n",
      "47 Iteration ...\n",
      "Epochs 47 finished !\n",
      "TOTAL LOSS : 105.8177719116211\n",
      "48 Iteration ...\n",
      "Epochs 48 finished !\n",
      "TOTAL LOSS : 105.8022232055664\n",
      "49 Iteration ...\n",
      "Epochs 49 finished !\n",
      "TOTAL LOSS : 105.78680419921875\n",
      "50 Iteration ...\n",
      "Epochs 50 finished !\n",
      "TOTAL LOSS : 105.77186584472656\n",
      "51 Iteration ...\n",
      "Epochs 51 finished !\n",
      "TOTAL LOSS : 105.75841522216797\n",
      "52 Iteration ...\n",
      "Epochs 52 finished !\n",
      "TOTAL LOSS : 105.74671936035156\n",
      "53 Iteration ...\n",
      "Epochs 53 finished !\n",
      "TOTAL LOSS : 105.7355728149414\n",
      "54 Iteration ...\n",
      "Epochs 54 finished !\n",
      "TOTAL LOSS : 105.72297668457031\n",
      "55 Iteration ...\n",
      "Epochs 55 finished !\n",
      "TOTAL LOSS : 105.70588684082031\n",
      "56 Iteration ...\n",
      "Epochs 56 finished !\n",
      "TOTAL LOSS : 105.68843078613281\n",
      "57 Iteration ...\n",
      "Epochs 57 finished !\n",
      "TOTAL LOSS : 105.67082977294922\n",
      "58 Iteration ...\n",
      "Epochs 58 finished !\n",
      "TOTAL LOSS : 105.6545639038086\n",
      "59 Iteration ...\n",
      "Epochs 59 finished !\n",
      "TOTAL LOSS : 105.63878631591797\n",
      "60 Iteration ...\n",
      "Epochs 60 finished !\n",
      "TOTAL LOSS : 105.6227035522461\n",
      "61 Iteration ...\n",
      "Epochs 61 finished !\n",
      "TOTAL LOSS : 105.60408020019531\n",
      "62 Iteration ...\n",
      "Epochs 62 finished !\n",
      "TOTAL LOSS : 105.58357238769531\n",
      "63 Iteration ...\n",
      "Epochs 63 finished !\n",
      "TOTAL LOSS : 105.5633773803711\n",
      "64 Iteration ...\n",
      "Epochs 64 finished !\n",
      "TOTAL LOSS : 105.54296112060547\n",
      "65 Iteration ...\n",
      "Epochs 65 finished !\n",
      "TOTAL LOSS : 105.522216796875\n",
      "66 Iteration ...\n",
      "Epochs 66 finished !\n",
      "TOTAL LOSS : 105.50154876708984\n",
      "67 Iteration ...\n",
      "Epochs 67 finished !\n",
      "TOTAL LOSS : 105.4806900024414\n",
      "68 Iteration ...\n",
      "Epochs 68 finished !\n",
      "TOTAL LOSS : 105.45655822753906\n",
      "69 Iteration ...\n",
      "Epochs 69 finished !\n",
      "TOTAL LOSS : 105.43157958984375\n",
      "70 Iteration ...\n",
      "Epochs 70 finished !\n",
      "TOTAL LOSS : 105.40587615966797\n",
      "71 Iteration ...\n",
      "Epochs 71 finished !\n",
      "TOTAL LOSS : 105.38048553466797\n",
      "72 Iteration ...\n",
      "Epochs 72 finished !\n",
      "TOTAL LOSS : 105.35662841796875\n",
      "73 Iteration ...\n",
      "Epochs 73 finished !\n",
      "TOTAL LOSS : 105.3332748413086\n",
      "74 Iteration ...\n",
      "Epochs 74 finished !\n",
      "TOTAL LOSS : 105.30928802490234\n",
      "75 Iteration ...\n",
      "Epochs 75 finished !\n",
      "TOTAL LOSS : 105.28553771972656\n",
      "76 Iteration ...\n",
      "Epochs 76 finished !\n",
      "TOTAL LOSS : 105.26201629638672\n",
      "77 Iteration ...\n",
      "Epochs 77 finished !\n",
      "TOTAL LOSS : 105.2379379272461\n",
      "78 Iteration ...\n",
      "Epochs 78 finished !\n",
      "TOTAL LOSS : 105.21400451660156\n",
      "79 Iteration ...\n",
      "Epochs 79 finished !\n",
      "TOTAL LOSS : 105.19038391113281\n",
      "80 Iteration ...\n",
      "Epochs 80 finished !\n",
      "TOTAL LOSS : 105.16680145263672\n",
      "81 Iteration ...\n",
      "Epochs 81 finished !\n",
      "TOTAL LOSS : 105.1430892944336\n",
      "82 Iteration ...\n",
      "Epochs 82 finished !\n",
      "TOTAL LOSS : 105.11907196044922\n",
      "83 Iteration ...\n",
      "Epochs 83 finished !\n",
      "TOTAL LOSS : 105.0947036743164\n",
      "84 Iteration ...\n",
      "Epochs 84 finished !\n",
      "TOTAL LOSS : 105.070068359375\n",
      "85 Iteration ...\n",
      "Epochs 85 finished !\n",
      "TOTAL LOSS : 105.04534149169922\n",
      "86 Iteration ...\n",
      "Epochs 86 finished !\n",
      "TOTAL LOSS : 105.02082824707031\n",
      "87 Iteration ...\n",
      "Epochs 87 finished !\n",
      "TOTAL LOSS : 104.99633026123047\n",
      "88 Iteration ...\n",
      "Epochs 88 finished !\n",
      "TOTAL LOSS : 104.97154998779297\n",
      "89 Iteration ...\n",
      "Epochs 89 finished !\n",
      "TOTAL LOSS : 104.94597625732422\n",
      "90 Iteration ...\n",
      "Epochs 90 finished !\n",
      "TOTAL LOSS : 104.9197006225586\n",
      "91 Iteration ...\n",
      "Epochs 91 finished !\n",
      "TOTAL LOSS : 104.89306640625\n",
      "92 Iteration ...\n",
      "Epochs 92 finished !\n",
      "TOTAL LOSS : 104.86622619628906\n",
      "93 Iteration ...\n",
      "Epochs 93 finished !\n",
      "TOTAL LOSS : 104.8394775390625\n",
      "94 Iteration ...\n",
      "Epochs 94 finished !\n",
      "TOTAL LOSS : 104.8126220703125\n",
      "95 Iteration ...\n",
      "Epochs 95 finished !\n",
      "TOTAL LOSS : 104.7857894897461\n",
      "96 Iteration ...\n",
      "Epochs 96 finished !\n",
      "TOTAL LOSS : 104.75859832763672\n",
      "97 Iteration ...\n",
      "Epochs 97 finished !\n",
      "TOTAL LOSS : 104.73097229003906\n",
      "98 Iteration ...\n",
      "Epochs 98 finished !\n",
      "TOTAL LOSS : 104.70259857177734\n",
      "99 Iteration ...\n",
      "Epochs 99 finished !\n",
      "TOTAL LOSS : 104.6744155883789\n",
      "100 Iteration ...\n",
      "Epochs 100 finished !\n",
      "TOTAL LOSS : 104.6458740234375\n",
      "101 Iteration ...\n",
      "Epochs 101 finished !\n",
      "TOTAL LOSS : 104.61726379394531\n",
      "102 Iteration ...\n",
      "Epochs 102 finished !\n",
      "TOTAL LOSS : 104.58837890625\n",
      "103 Iteration ...\n",
      "Epochs 103 finished !\n",
      "TOTAL LOSS : 104.55952453613281\n",
      "104 Iteration ...\n",
      "Epochs 104 finished !\n",
      "TOTAL LOSS : 104.53038787841797\n",
      "105 Iteration ...\n",
      "Epochs 105 finished !\n",
      "TOTAL LOSS : 104.50146484375\n",
      "106 Iteration ...\n",
      "Epochs 106 finished !\n",
      "TOTAL LOSS : 104.47242736816406\n",
      "107 Iteration ...\n",
      "Epochs 107 finished !\n",
      "TOTAL LOSS : 104.4431381225586\n",
      "108 Iteration ...\n",
      "Epochs 108 finished !\n",
      "TOTAL LOSS : 104.4135513305664\n",
      "109 Iteration ...\n",
      "Epochs 109 finished !\n",
      "TOTAL LOSS : 104.3836669921875\n",
      "110 Iteration ...\n",
      "Epochs 110 finished !\n",
      "TOTAL LOSS : 104.3536148071289\n",
      "111 Iteration ...\n",
      "Epochs 111 finished !\n",
      "TOTAL LOSS : 104.3232421875\n",
      "112 Iteration ...\n",
      "Epochs 112 finished !\n",
      "TOTAL LOSS : 104.2921371459961\n",
      "113 Iteration ...\n",
      "Epochs 113 finished !\n",
      "TOTAL LOSS : 104.26152801513672\n",
      "114 Iteration ...\n",
      "Epochs 114 finished !\n",
      "TOTAL LOSS : 104.23055267333984\n",
      "115 Iteration ...\n",
      "Epochs 115 finished !\n",
      "TOTAL LOSS : 104.19905090332031\n",
      "116 Iteration ...\n",
      "Epochs 116 finished !\n",
      "TOTAL LOSS : 104.16719055175781\n",
      "117 Iteration ...\n",
      "Epochs 117 finished !\n",
      "TOTAL LOSS : 104.13542938232422\n",
      "118 Iteration ...\n",
      "Epochs 118 finished !\n",
      "TOTAL LOSS : 104.10343170166016\n",
      "119 Iteration ...\n",
      "Epochs 119 finished !\n",
      "TOTAL LOSS : 104.07125091552734\n",
      "120 Iteration ...\n",
      "Epochs 120 finished !\n",
      "TOTAL LOSS : 104.038818359375\n",
      "121 Iteration ...\n",
      "Epochs 121 finished !\n",
      "TOTAL LOSS : 104.0057144165039\n",
      "122 Iteration ...\n",
      "Epochs 122 finished !\n",
      "TOTAL LOSS : 103.9716567993164\n",
      "123 Iteration ...\n",
      "Epochs 123 finished !\n",
      "TOTAL LOSS : 103.9380874633789\n",
      "124 Iteration ...\n",
      "Epochs 124 finished !\n",
      "TOTAL LOSS : 103.90486145019531\n",
      "125 Iteration ...\n",
      "Epochs 125 finished !\n",
      "TOTAL LOSS : 103.87129211425781\n",
      "126 Iteration ...\n",
      "Epochs 126 finished !\n",
      "TOTAL LOSS : 103.8367919921875\n",
      "127 Iteration ...\n",
      "Epochs 127 finished !\n",
      "TOTAL LOSS : 103.80224609375\n",
      "128 Iteration ...\n",
      "Epochs 128 finished !\n",
      "TOTAL LOSS : 103.76741027832031\n",
      "129 Iteration ...\n",
      "Epochs 129 finished !\n",
      "TOTAL LOSS : 103.7320556640625\n",
      "130 Iteration ...\n",
      "Epochs 130 finished !\n",
      "TOTAL LOSS : 103.69649505615234\n",
      "131 Iteration ...\n",
      "Epochs 131 finished !\n",
      "TOTAL LOSS : 103.66048431396484\n",
      "132 Iteration ...\n",
      "Epochs 132 finished !\n",
      "TOTAL LOSS : 103.6240234375\n",
      "133 Iteration ...\n",
      "Epochs 133 finished !\n",
      "TOTAL LOSS : 103.5875015258789\n",
      "134 Iteration ...\n",
      "Epochs 134 finished !\n",
      "TOTAL LOSS : 103.55078125\n",
      "135 Iteration ...\n",
      "Epochs 135 finished !\n",
      "TOTAL LOSS : 103.51336669921875\n",
      "136 Iteration ...\n",
      "Epochs 136 finished !\n",
      "TOTAL LOSS : 103.47589111328125\n",
      "137 Iteration ...\n",
      "Epochs 137 finished !\n",
      "TOTAL LOSS : 103.43804931640625\n",
      "138 Iteration ...\n",
      "Epochs 138 finished !\n",
      "TOTAL LOSS : 103.39959716796875\n",
      "139 Iteration ...\n",
      "Epochs 139 finished !\n",
      "TOTAL LOSS : 103.3608627319336\n",
      "140 Iteration ...\n",
      "Epochs 140 finished !\n",
      "TOTAL LOSS : 103.3219985961914\n",
      "141 Iteration ...\n",
      "Epochs 141 finished !\n",
      "TOTAL LOSS : 103.28301239013672\n",
      "142 Iteration ...\n",
      "Epochs 142 finished !\n",
      "TOTAL LOSS : 103.2436752319336\n",
      "143 Iteration ...\n",
      "Epochs 143 finished !\n",
      "TOTAL LOSS : 103.2041015625\n",
      "144 Iteration ...\n",
      "Epochs 144 finished !\n",
      "TOTAL LOSS : 103.16410064697266\n",
      "145 Iteration ...\n",
      "Epochs 145 finished !\n",
      "TOTAL LOSS : 103.12359619140625\n",
      "146 Iteration ...\n",
      "Epochs 146 finished !\n",
      "TOTAL LOSS : 103.08265686035156\n",
      "147 Iteration ...\n",
      "Epochs 147 finished !\n",
      "TOTAL LOSS : 103.0412826538086\n",
      "148 Iteration ...\n",
      "Epochs 148 finished !\n",
      "TOTAL LOSS : 102.99995422363281\n",
      "149 Iteration ...\n",
      "Epochs 149 finished !\n",
      "TOTAL LOSS : 102.95854949951172\n",
      "150 Iteration ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lambda_ \u001b[38;5;129;01min\u001b[39;00m lambda_values : \n\u001b[0;32m      6\u001b[0m     Phi_functions,optimizers \u001b[38;5;241m=\u001b[39m Phi_NN()\n\u001b[1;32m----> 7\u001b[0m     evaluation \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_iteration\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlambda_\u001b[49m\u001b[43m,\u001b[49m\u001b[43mPhi_functions\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     P[lambda_] \u001b[38;5;241m=\u001b[39m evaluation\n",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36mtrain_evaluate\u001b[1;34m(n_iteration, lambda_, Phi_functions, optimizers)\u001b[0m\n\u001b[0;32m    117\u001b[0m optimizers[l]\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m    118\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m--> 119\u001b[0m \u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;66;03m#print(f\"model trained ! ...\")\u001b[39;00m\n\u001b[0;32m    121\u001b[0m total_loss\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39mloss\n",
      "File \u001b[1;32mc:\\Users\\moham\\.conda\\envs\\torch\\lib\\site-packages\\torch\\optim\\optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\moham\\.conda\\envs\\torch\\lib\\site-packages\\torch\\optim\\optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 33\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[1;32mc:\\Users\\moham\\.conda\\envs\\torch\\lib\\site-packages\\torch\\optim\\adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    130\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    133\u001b[0m         group,\n\u001b[0;32m    134\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    139\u001b[0m         state_steps)\n\u001b[1;32m--> 141\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\moham\\.conda\\envs\\torch\\lib\\site-packages\\torch\\optim\\adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    279\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 281\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\moham\\.conda\\envs\\torch\\lib\\site-packages\\torch\\optim\\adam.py:439\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    436\u001b[0m params_ \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mview_as_real(x) \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(x) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m device_params]\n\u001b[0;32m    438\u001b[0m \u001b[38;5;66;03m# update steps\u001b[39;00m\n\u001b[1;32m--> 439\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_add_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_state_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight_decay \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    442\u001b[0m     device_grads \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_foreach_add(device_grads, device_params, alpha\u001b[38;5;241m=\u001b[39mweight_decay)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "P = {}\n",
    "\n",
    "\n",
    "for lambda_ in lambda_values : \n",
    "\n",
    "    Phi_functions,optimizers = Phi_NN()\n",
    "    evaluation = train_evaluate(n_iteration,lambda_,Phi_functions,optimizers)\n",
    "    P[lambda_] = evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'P' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mconvolve(data, np\u001b[38;5;241m.\u001b[39mones(window_size)\u001b[38;5;241m/\u001b[39mwindow_size, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lambda_ \u001b[38;5;129;01min\u001b[39;00m lambda_values[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] : \n\u001b[1;32m----> 6\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot(moving_average(\u001b[43mP\u001b[49m[lambda_][:\u001b[38;5;241m100\u001b[39m]),label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mlambda$=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(lambda_))\n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRelative error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNb epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'P' is not defined"
     ]
    }
   ],
   "source": [
    "def moving_average(data, window_size=5):\n",
    "    return np.convolve(data, np.ones(window_size)/window_size, mode='valid')\n",
    "\n",
    "\n",
    "for lambda_ in lambda_values[1:-1] : \n",
    "    plt.plot(moving_average(P[lambda_][:100]),label = \"$\\lambda$=\"+str(lambda_))\n",
    "\n",
    "\n",
    "plt.ylabel(\"Relative error\")\n",
    "plt.xlabel(\"Nb epochs\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Iteration ...\n",
      "Epochs 1 finished !\n",
      "TOTAL LOSS : 6.4936723709106445\n",
      "2 Iteration ...\n",
      "Epochs 2 finished !\n",
      "TOTAL LOSS : 6.8939642906188965\n",
      "3 Iteration ...\n",
      "Epochs 3 finished !\n",
      "TOTAL LOSS : 6.799124240875244\n",
      "4 Iteration ...\n",
      "Epochs 4 finished !\n",
      "TOTAL LOSS : 6.9804368019104\n",
      "5 Iteration ...\n",
      "Epochs 5 finished !\n",
      "TOTAL LOSS : 6.475802898406982\n",
      "6 Iteration ...\n",
      "Epochs 6 finished !\n",
      "TOTAL LOSS : 6.776081085205078\n",
      "7 Iteration ...\n",
      "Epochs 7 finished !\n",
      "TOTAL LOSS : 6.995156288146973\n",
      "8 Iteration ...\n",
      "Epochs 8 finished !\n",
      "TOTAL LOSS : 6.851934909820557\n",
      "9 Iteration ...\n",
      "Epochs 9 finished !\n",
      "TOTAL LOSS : 6.676141262054443\n",
      "10 Iteration ...\n",
      "Epochs 10 finished !\n",
      "TOTAL LOSS : 6.734472751617432\n",
      "11 Iteration ...\n",
      "Epochs 11 finished !\n",
      "TOTAL LOSS : 6.954174041748047\n",
      "12 Iteration ...\n",
      "Epochs 12 finished !\n",
      "TOTAL LOSS : 7.1309099197387695\n",
      "13 Iteration ...\n",
      "Epochs 13 finished !\n",
      "TOTAL LOSS : 6.526664733886719\n",
      "14 Iteration ...\n",
      "Epochs 14 finished !\n",
      "TOTAL LOSS : 6.701831340789795\n",
      "15 Iteration ...\n",
      "Epochs 15 finished !\n",
      "TOTAL LOSS : 6.697305202484131\n",
      "16 Iteration ...\n",
      "Epochs 16 finished !\n",
      "TOTAL LOSS : 6.89318323135376\n",
      "17 Iteration ...\n",
      "Epochs 17 finished !\n",
      "TOTAL LOSS : 6.862099647521973\n",
      "18 Iteration ...\n",
      "Epochs 18 finished !\n",
      "TOTAL LOSS : 6.835341930389404\n",
      "19 Iteration ...\n",
      "Epochs 19 finished !\n",
      "TOTAL LOSS : 6.260621547698975\n",
      "20 Iteration ...\n",
      "Epochs 20 finished !\n",
      "TOTAL LOSS : 6.72091817855835\n",
      "21 Iteration ...\n",
      "Epochs 21 finished !\n",
      "TOTAL LOSS : 6.878821849822998\n",
      "22 Iteration ...\n",
      "Epochs 22 finished !\n",
      "TOTAL LOSS : 6.920828342437744\n",
      "23 Iteration ...\n",
      "Epochs 23 finished !\n",
      "TOTAL LOSS : 6.9648756980896\n",
      "24 Iteration ...\n",
      "Epochs 24 finished !\n",
      "TOTAL LOSS : 6.4804816246032715\n",
      "25 Iteration ...\n",
      "Epochs 25 finished !\n",
      "TOTAL LOSS : 6.762786865234375\n",
      "26 Iteration ...\n",
      "Epochs 26 finished !\n",
      "TOTAL LOSS : 6.921061038970947\n",
      "27 Iteration ...\n",
      "Epochs 27 finished !\n",
      "TOTAL LOSS : 7.1794304847717285\n",
      "28 Iteration ...\n",
      "Epochs 28 finished !\n",
      "TOTAL LOSS : 6.903407573699951\n",
      "29 Iteration ...\n",
      "Epochs 29 finished !\n",
      "TOTAL LOSS : 6.901496887207031\n",
      "30 Iteration ...\n",
      "Epochs 30 finished !\n",
      "TOTAL LOSS : 6.782596588134766\n",
      "31 Iteration ...\n",
      "Epochs 31 finished !\n",
      "TOTAL LOSS : 7.054450988769531\n",
      "32 Iteration ...\n",
      "Epochs 32 finished !\n",
      "TOTAL LOSS : 6.873195171356201\n",
      "33 Iteration ...\n",
      "Epochs 33 finished !\n",
      "TOTAL LOSS : 6.580628395080566\n",
      "34 Iteration ...\n",
      "Epochs 34 finished !\n",
      "TOTAL LOSS : 7.033824443817139\n",
      "35 Iteration ...\n",
      "Epochs 35 finished !\n",
      "TOTAL LOSS : 6.660167694091797\n",
      "36 Iteration ...\n",
      "Epochs 36 finished !\n",
      "TOTAL LOSS : 6.789673805236816\n",
      "37 Iteration ...\n",
      "Epochs 37 finished !\n",
      "TOTAL LOSS : 7.193542003631592\n",
      "38 Iteration ...\n",
      "Epochs 38 finished !\n",
      "TOTAL LOSS : 6.793923854827881\n",
      "39 Iteration ...\n",
      "Epochs 39 finished !\n",
      "TOTAL LOSS : 7.145919322967529\n",
      "40 Iteration ...\n",
      "Epochs 40 finished !\n",
      "TOTAL LOSS : 7.017446041107178\n",
      "41 Iteration ...\n",
      "Epochs 41 finished !\n",
      "TOTAL LOSS : 6.682412624359131\n",
      "42 Iteration ...\n",
      "Epochs 42 finished !\n",
      "TOTAL LOSS : 7.0017900466918945\n",
      "43 Iteration ...\n",
      "Epochs 43 finished !\n",
      "TOTAL LOSS : 7.1512885093688965\n",
      "44 Iteration ...\n",
      "Epochs 44 finished !\n",
      "TOTAL LOSS : 7.131795406341553\n",
      "45 Iteration ...\n",
      "Epochs 45 finished !\n",
      "TOTAL LOSS : 6.900825500488281\n",
      "46 Iteration ...\n",
      "Epochs 46 finished !\n",
      "TOTAL LOSS : 7.107944011688232\n",
      "47 Iteration ...\n",
      "Epochs 47 finished !\n",
      "TOTAL LOSS : 7.271620273590088\n",
      "48 Iteration ...\n",
      "Epochs 48 finished !\n",
      "TOTAL LOSS : 7.313655376434326\n",
      "49 Iteration ...\n",
      "Epochs 49 finished !\n",
      "TOTAL LOSS : 6.863797664642334\n",
      "50 Iteration ...\n",
      "Epochs 50 finished !\n",
      "TOTAL LOSS : 6.642402172088623\n",
      "51 Iteration ...\n",
      "Epochs 51 finished !\n",
      "TOTAL LOSS : 6.8497748374938965\n",
      "52 Iteration ...\n",
      "Epochs 52 finished !\n",
      "TOTAL LOSS : 7.056918621063232\n",
      "53 Iteration ...\n",
      "Epochs 53 finished !\n",
      "TOTAL LOSS : 7.222352027893066\n",
      "54 Iteration ...\n",
      "Epochs 54 finished !\n",
      "TOTAL LOSS : 7.533697605133057\n",
      "55 Iteration ...\n",
      "Epochs 55 finished !\n",
      "TOTAL LOSS : 7.0887370109558105\n",
      "56 Iteration ...\n",
      "Epochs 56 finished !\n",
      "TOTAL LOSS : 6.930850982666016\n",
      "57 Iteration ...\n",
      "Epochs 57 finished !\n",
      "TOTAL LOSS : 7.344228267669678\n",
      "58 Iteration ...\n",
      "Epochs 58 finished !\n",
      "TOTAL LOSS : 6.89320707321167\n",
      "59 Iteration ...\n",
      "Epochs 59 finished !\n",
      "TOTAL LOSS : 7.1183319091796875\n",
      "60 Iteration ...\n",
      "Epochs 60 finished !\n",
      "TOTAL LOSS : 7.231762886047363\n",
      "61 Iteration ...\n",
      "Epochs 61 finished !\n",
      "TOTAL LOSS : 7.185111999511719\n",
      "62 Iteration ...\n",
      "Epochs 62 finished !\n",
      "TOTAL LOSS : 7.3746514320373535\n",
      "63 Iteration ...\n",
      "Epochs 63 finished !\n",
      "TOTAL LOSS : 7.1831183433532715\n",
      "64 Iteration ...\n",
      "Epochs 64 finished !\n",
      "TOTAL LOSS : 7.308571815490723\n",
      "65 Iteration ...\n",
      "Epochs 65 finished !\n",
      "TOTAL LOSS : 7.274420261383057\n",
      "66 Iteration ...\n",
      "Epochs 66 finished !\n",
      "TOTAL LOSS : 7.631352424621582\n",
      "67 Iteration ...\n",
      "Epochs 67 finished !\n",
      "TOTAL LOSS : 7.494178771972656\n",
      "68 Iteration ...\n",
      "Epochs 68 finished !\n",
      "TOTAL LOSS : 7.268834590911865\n",
      "69 Iteration ...\n",
      "Epochs 69 finished !\n",
      "TOTAL LOSS : 7.1608171463012695\n",
      "70 Iteration ...\n",
      "Epochs 70 finished !\n",
      "TOTAL LOSS : 6.955468654632568\n",
      "71 Iteration ...\n",
      "Epochs 71 finished !\n",
      "TOTAL LOSS : 7.2262282371521\n",
      "72 Iteration ...\n",
      "Epochs 72 finished !\n",
      "TOTAL LOSS : 7.319352149963379\n",
      "73 Iteration ...\n",
      "Epochs 73 finished !\n",
      "TOTAL LOSS : 7.443336009979248\n",
      "74 Iteration ...\n",
      "Epochs 74 finished !\n",
      "TOTAL LOSS : 7.408502101898193\n",
      "75 Iteration ...\n",
      "Epochs 75 finished !\n",
      "TOTAL LOSS : 7.8520026206970215\n",
      "76 Iteration ...\n",
      "Epochs 76 finished !\n",
      "TOTAL LOSS : 7.3057475090026855\n",
      "77 Iteration ...\n",
      "Epochs 77 finished !\n",
      "TOTAL LOSS : 7.495888710021973\n",
      "78 Iteration ...\n",
      "Epochs 78 finished !\n",
      "TOTAL LOSS : 7.582756042480469\n",
      "79 Iteration ...\n",
      "Epochs 79 finished !\n",
      "TOTAL LOSS : 7.538815498352051\n",
      "80 Iteration ...\n",
      "Epochs 80 finished !\n",
      "TOTAL LOSS : 7.380535125732422\n",
      "81 Iteration ...\n",
      "Epochs 81 finished !\n",
      "TOTAL LOSS : 7.481168270111084\n",
      "82 Iteration ...\n",
      "Epochs 82 finished !\n",
      "TOTAL LOSS : 7.406739234924316\n",
      "83 Iteration ...\n",
      "Epochs 83 finished !\n",
      "TOTAL LOSS : 7.886167049407959\n",
      "84 Iteration ...\n",
      "Epochs 84 finished !\n",
      "TOTAL LOSS : 7.1967902183532715\n",
      "85 Iteration ...\n",
      "Epochs 85 finished !\n",
      "TOTAL LOSS : 7.1955766677856445\n",
      "86 Iteration ...\n",
      "Epochs 86 finished !\n",
      "TOTAL LOSS : 7.538669586181641\n",
      "87 Iteration ...\n",
      "Epochs 87 finished !\n",
      "TOTAL LOSS : 7.1824259757995605\n",
      "88 Iteration ...\n",
      "Epochs 88 finished !\n",
      "TOTAL LOSS : 7.648410797119141\n",
      "89 Iteration ...\n",
      "Epochs 89 finished !\n",
      "TOTAL LOSS : 7.7693376541137695\n",
      "90 Iteration ...\n",
      "Epochs 90 finished !\n",
      "TOTAL LOSS : 7.632271766662598\n",
      "91 Iteration ...\n",
      "Epochs 91 finished !\n",
      "TOTAL LOSS : 7.720612525939941\n",
      "92 Iteration ...\n",
      "Epochs 92 finished !\n",
      "TOTAL LOSS : 7.315451145172119\n",
      "93 Iteration ...\n",
      "Epochs 93 finished !\n",
      "TOTAL LOSS : 7.582056522369385\n",
      "94 Iteration ...\n",
      "Epochs 94 finished !\n",
      "TOTAL LOSS : 7.6208176612854\n",
      "95 Iteration ...\n",
      "Epochs 95 finished !\n",
      "TOTAL LOSS : 7.4095377922058105\n",
      "96 Iteration ...\n",
      "Epochs 96 finished !\n",
      "TOTAL LOSS : 7.95517110824585\n",
      "97 Iteration ...\n",
      "Epochs 97 finished !\n",
      "TOTAL LOSS : 7.441651821136475\n",
      "98 Iteration ...\n",
      "Epochs 98 finished !\n",
      "TOTAL LOSS : 8.024280548095703\n",
      "99 Iteration ...\n",
      "Epochs 99 finished !\n",
      "TOTAL LOSS : 7.513411998748779\n",
      "100 Iteration ...\n",
      "Epochs 100 finished !\n",
      "TOTAL LOSS : 7.729086399078369\n",
      "101 Iteration ...\n",
      "Epochs 101 finished !\n",
      "TOTAL LOSS : 8.03847885131836\n",
      "102 Iteration ...\n",
      "Epochs 102 finished !\n",
      "TOTAL LOSS : 7.74440860748291\n",
      "103 Iteration ...\n",
      "Epochs 103 finished !\n",
      "TOTAL LOSS : 7.634500026702881\n",
      "104 Iteration ...\n",
      "Epochs 104 finished !\n",
      "TOTAL LOSS : 7.664897918701172\n",
      "105 Iteration ...\n",
      "Epochs 105 finished !\n",
      "TOTAL LOSS : 7.400616645812988\n",
      "106 Iteration ...\n",
      "Epochs 106 finished !\n",
      "TOTAL LOSS : 7.790809154510498\n",
      "107 Iteration ...\n",
      "Epochs 107 finished !\n",
      "TOTAL LOSS : 8.037092208862305\n",
      "108 Iteration ...\n",
      "Epochs 108 finished !\n",
      "TOTAL LOSS : 7.6737260818481445\n",
      "109 Iteration ...\n",
      "Epochs 109 finished !\n",
      "TOTAL LOSS : 7.358593940734863\n",
      "110 Iteration ...\n",
      "Epochs 110 finished !\n",
      "TOTAL LOSS : 7.82567834854126\n",
      "111 Iteration ...\n",
      "Epochs 111 finished !\n",
      "TOTAL LOSS : 7.590213775634766\n",
      "112 Iteration ...\n",
      "Epochs 112 finished !\n",
      "TOTAL LOSS : 7.544796943664551\n",
      "113 Iteration ...\n",
      "Epochs 113 finished !\n",
      "TOTAL LOSS : 7.1985015869140625\n",
      "114 Iteration ...\n",
      "Epochs 114 finished !\n",
      "TOTAL LOSS : 7.14651346206665\n",
      "115 Iteration ...\n",
      "Epochs 115 finished !\n",
      "TOTAL LOSS : 7.590844631195068\n",
      "116 Iteration ...\n",
      "Epochs 116 finished !\n",
      "TOTAL LOSS : 7.119212627410889\n",
      "117 Iteration ...\n",
      "Epochs 117 finished !\n",
      "TOTAL LOSS : 7.912278652191162\n",
      "118 Iteration ...\n",
      "Epochs 118 finished !\n",
      "TOTAL LOSS : 7.5255608558654785\n",
      "119 Iteration ...\n",
      "Epochs 119 finished !\n",
      "TOTAL LOSS : 7.660635471343994\n",
      "120 Iteration ...\n",
      "Epochs 120 finished !\n",
      "TOTAL LOSS : 7.77327299118042\n",
      "121 Iteration ...\n",
      "Epochs 121 finished !\n",
      "TOTAL LOSS : 7.87896203994751\n",
      "122 Iteration ...\n",
      "Epochs 122 finished !\n",
      "TOTAL LOSS : 7.655059814453125\n",
      "123 Iteration ...\n",
      "Epochs 123 finished !\n",
      "TOTAL LOSS : 7.749989986419678\n",
      "124 Iteration ...\n",
      "Epochs 124 finished !\n",
      "TOTAL LOSS : 7.670770168304443\n",
      "125 Iteration ...\n",
      "Epochs 125 finished !\n",
      "TOTAL LOSS : 7.627118110656738\n",
      "126 Iteration ...\n",
      "Epochs 126 finished !\n",
      "TOTAL LOSS : 7.602232456207275\n",
      "127 Iteration ...\n",
      "Epochs 127 finished !\n",
      "TOTAL LOSS : 7.630587100982666\n",
      "128 Iteration ...\n",
      "Epochs 128 finished !\n",
      "TOTAL LOSS : 7.729588985443115\n",
      "129 Iteration ...\n",
      "Epochs 129 finished !\n",
      "TOTAL LOSS : 7.2826995849609375\n",
      "130 Iteration ...\n",
      "Epochs 130 finished !\n",
      "TOTAL LOSS : 7.819076061248779\n",
      "131 Iteration ...\n",
      "Epochs 131 finished !\n",
      "TOTAL LOSS : 7.664519786834717\n",
      "132 Iteration ...\n",
      "Epochs 132 finished !\n",
      "TOTAL LOSS : 8.013193130493164\n",
      "133 Iteration ...\n",
      "Epochs 133 finished !\n",
      "TOTAL LOSS : 7.374619960784912\n",
      "134 Iteration ...\n",
      "Epochs 134 finished !\n",
      "TOTAL LOSS : 7.643619060516357\n",
      "135 Iteration ...\n",
      "Epochs 135 finished !\n",
      "TOTAL LOSS : 8.224238395690918\n",
      "136 Iteration ...\n",
      "Epochs 136 finished !\n",
      "TOTAL LOSS : 7.596771240234375\n",
      "137 Iteration ...\n",
      "Epochs 137 finished !\n",
      "TOTAL LOSS : 8.158831596374512\n",
      "138 Iteration ...\n",
      "Epochs 138 finished !\n",
      "TOTAL LOSS : 7.895195007324219\n",
      "139 Iteration ...\n",
      "Epochs 139 finished !\n",
      "TOTAL LOSS : 8.101455688476562\n",
      "140 Iteration ...\n",
      "Epochs 140 finished !\n",
      "TOTAL LOSS : 7.796940803527832\n",
      "141 Iteration ...\n",
      "Epochs 141 finished !\n",
      "TOTAL LOSS : 7.805259704589844\n",
      "142 Iteration ...\n",
      "Epochs 142 finished !\n",
      "TOTAL LOSS : 7.855774879455566\n",
      "143 Iteration ...\n",
      "Epochs 143 finished !\n",
      "TOTAL LOSS : 7.817470073699951\n",
      "144 Iteration ...\n",
      "Epochs 144 finished !\n",
      "TOTAL LOSS : 8.025179862976074\n",
      "145 Iteration ...\n",
      "Epochs 145 finished !\n",
      "TOTAL LOSS : 7.572535991668701\n",
      "146 Iteration ...\n",
      "Epochs 146 finished !\n",
      "TOTAL LOSS : 7.984189033508301\n",
      "147 Iteration ...\n",
      "Epochs 147 finished !\n",
      "TOTAL LOSS : 7.614414215087891\n",
      "148 Iteration ...\n",
      "Epochs 148 finished !\n",
      "TOTAL LOSS : 7.737026214599609\n",
      "149 Iteration ...\n",
      "Epochs 149 finished !\n",
      "TOTAL LOSS : 7.75110387802124\n",
      "150 Iteration ...\n",
      "Epochs 150 finished !\n",
      "TOTAL LOSS : 7.666220188140869\n",
      "151 Iteration ...\n",
      "Epochs 151 finished !\n",
      "TOTAL LOSS : 7.9807305335998535\n",
      "152 Iteration ...\n",
      "Epochs 152 finished !\n",
      "TOTAL LOSS : 7.706881999969482\n",
      "153 Iteration ...\n",
      "Epochs 153 finished !\n",
      "TOTAL LOSS : 7.693782806396484\n",
      "154 Iteration ...\n",
      "Epochs 154 finished !\n",
      "TOTAL LOSS : 7.620610237121582\n",
      "155 Iteration ...\n",
      "Epochs 155 finished !\n",
      "TOTAL LOSS : 7.720149993896484\n",
      "156 Iteration ...\n",
      "Epochs 156 finished !\n",
      "TOTAL LOSS : 8.073185920715332\n",
      "157 Iteration ...\n",
      "Epochs 157 finished !\n",
      "TOTAL LOSS : 7.482512950897217\n",
      "158 Iteration ...\n",
      "Epochs 158 finished !\n",
      "TOTAL LOSS : 8.206741333007812\n",
      "159 Iteration ...\n",
      "Epochs 159 finished !\n",
      "TOTAL LOSS : 7.548370361328125\n",
      "160 Iteration ...\n",
      "Epochs 160 finished !\n",
      "TOTAL LOSS : 7.147528171539307\n",
      "161 Iteration ...\n",
      "Epochs 161 finished !\n",
      "TOTAL LOSS : 7.243657112121582\n",
      "162 Iteration ...\n",
      "Epochs 162 finished !\n",
      "TOTAL LOSS : 7.338894844055176\n",
      "163 Iteration ...\n",
      "Epochs 163 finished !\n",
      "TOTAL LOSS : 7.793679237365723\n",
      "164 Iteration ...\n",
      "Epochs 164 finished !\n",
      "TOTAL LOSS : 7.351548194885254\n",
      "165 Iteration ...\n",
      "Epochs 165 finished !\n",
      "TOTAL LOSS : 7.8560028076171875\n",
      "166 Iteration ...\n",
      "Epochs 166 finished !\n",
      "TOTAL LOSS : 7.657437324523926\n",
      "167 Iteration ...\n",
      "Epochs 167 finished !\n",
      "TOTAL LOSS : 7.703228950500488\n",
      "168 Iteration ...\n",
      "Epochs 168 finished !\n",
      "TOTAL LOSS : 7.8646111488342285\n",
      "169 Iteration ...\n",
      "Epochs 169 finished !\n",
      "TOTAL LOSS : 7.70551061630249\n",
      "170 Iteration ...\n",
      "Epochs 170 finished !\n",
      "TOTAL LOSS : 7.61091947555542\n",
      "171 Iteration ...\n",
      "Epochs 171 finished !\n",
      "TOTAL LOSS : 7.804848670959473\n",
      "172 Iteration ...\n",
      "Epochs 172 finished !\n",
      "TOTAL LOSS : 7.478446960449219\n",
      "173 Iteration ...\n",
      "Epochs 173 finished !\n",
      "TOTAL LOSS : 7.335792541503906\n",
      "174 Iteration ...\n",
      "Epochs 174 finished !\n",
      "TOTAL LOSS : 7.974853515625\n",
      "175 Iteration ...\n",
      "Epochs 175 finished !\n",
      "TOTAL LOSS : 7.554903507232666\n",
      "176 Iteration ...\n",
      "Epochs 176 finished !\n",
      "TOTAL LOSS : 7.975213527679443\n",
      "177 Iteration ...\n",
      "Epochs 177 finished !\n",
      "TOTAL LOSS : 7.587711334228516\n",
      "178 Iteration ...\n",
      "Epochs 178 finished !\n",
      "TOTAL LOSS : 7.757440090179443\n",
      "179 Iteration ...\n",
      "Epochs 179 finished !\n",
      "TOTAL LOSS : 7.644627571105957\n",
      "180 Iteration ...\n",
      "Epochs 180 finished !\n",
      "TOTAL LOSS : 7.710292816162109\n",
      "181 Iteration ...\n",
      "Epochs 181 finished !\n",
      "TOTAL LOSS : 7.187878608703613\n",
      "182 Iteration ...\n",
      "Epochs 182 finished !\n",
      "TOTAL LOSS : 7.3629021644592285\n",
      "183 Iteration ...\n",
      "Epochs 183 finished !\n",
      "TOTAL LOSS : 8.041865348815918\n",
      "184 Iteration ...\n",
      "Epochs 184 finished !\n",
      "TOTAL LOSS : 7.893679141998291\n",
      "185 Iteration ...\n",
      "Epochs 185 finished !\n",
      "TOTAL LOSS : 7.744669437408447\n",
      "186 Iteration ...\n",
      "Epochs 186 finished !\n",
      "TOTAL LOSS : 7.380643367767334\n",
      "187 Iteration ...\n",
      "Epochs 187 finished !\n",
      "TOTAL LOSS : 7.5926194190979\n",
      "188 Iteration ...\n",
      "Epochs 188 finished !\n",
      "TOTAL LOSS : 7.207798004150391\n",
      "189 Iteration ...\n",
      "Epochs 189 finished !\n",
      "TOTAL LOSS : 7.908725738525391\n",
      "190 Iteration ...\n",
      "Epochs 190 finished !\n",
      "TOTAL LOSS : 7.890527248382568\n",
      "191 Iteration ...\n",
      "Epochs 191 finished !\n",
      "TOTAL LOSS : 7.797696590423584\n",
      "192 Iteration ...\n",
      "Epochs 192 finished !\n",
      "TOTAL LOSS : 8.135058403015137\n",
      "193 Iteration ...\n",
      "Epochs 193 finished !\n",
      "TOTAL LOSS : 7.75603723526001\n",
      "194 Iteration ...\n",
      "Epochs 194 finished !\n",
      "TOTAL LOSS : 7.607758522033691\n",
      "195 Iteration ...\n",
      "Epochs 195 finished !\n",
      "TOTAL LOSS : 7.373240947723389\n",
      "196 Iteration ...\n",
      "Epochs 196 finished !\n",
      "TOTAL LOSS : 7.631251811981201\n",
      "197 Iteration ...\n",
      "Epochs 197 finished !\n",
      "TOTAL LOSS : 7.905450344085693\n",
      "198 Iteration ...\n",
      "Epochs 198 finished !\n",
      "TOTAL LOSS : 7.571131229400635\n",
      "199 Iteration ...\n",
      "Epochs 199 finished !\n",
      "TOTAL LOSS : 7.941342830657959\n",
      "200 Iteration ...\n",
      "Epochs 200 finished !\n",
      "TOTAL LOSS : 7.974467754364014\n",
      "201 Iteration ...\n",
      "Epochs 201 finished !\n",
      "TOTAL LOSS : 7.720695495605469\n",
      "202 Iteration ...\n",
      "Epochs 202 finished !\n",
      "TOTAL LOSS : 7.840930938720703\n",
      "203 Iteration ...\n",
      "Epochs 203 finished !\n",
      "TOTAL LOSS : 7.861804485321045\n",
      "204 Iteration ...\n",
      "Epochs 204 finished !\n",
      "TOTAL LOSS : 7.7700653076171875\n",
      "205 Iteration ...\n",
      "Epochs 205 finished !\n",
      "TOTAL LOSS : 7.873072147369385\n",
      "206 Iteration ...\n",
      "Epochs 206 finished !\n",
      "TOTAL LOSS : 7.958510875701904\n",
      "207 Iteration ...\n",
      "Epochs 207 finished !\n",
      "TOTAL LOSS : 7.759527683258057\n",
      "208 Iteration ...\n",
      "Epochs 208 finished !\n",
      "TOTAL LOSS : 7.742946624755859\n",
      "209 Iteration ...\n",
      "Epochs 209 finished !\n",
      "TOTAL LOSS : 7.3839545249938965\n",
      "210 Iteration ...\n",
      "Epochs 210 finished !\n",
      "TOTAL LOSS : 7.6864447593688965\n",
      "211 Iteration ...\n",
      "Epochs 211 finished !\n",
      "TOTAL LOSS : 7.585736274719238\n",
      "212 Iteration ...\n",
      "Epochs 212 finished !\n",
      "TOTAL LOSS : 7.676021099090576\n",
      "213 Iteration ...\n",
      "Epochs 213 finished !\n",
      "TOTAL LOSS : 7.625984191894531\n",
      "214 Iteration ...\n",
      "Epochs 214 finished !\n",
      "TOTAL LOSS : 7.527122497558594\n",
      "215 Iteration ...\n",
      "Epochs 215 finished !\n",
      "TOTAL LOSS : 7.7434282302856445\n",
      "216 Iteration ...\n",
      "Epochs 216 finished !\n",
      "TOTAL LOSS : 7.572085857391357\n",
      "217 Iteration ...\n",
      "Epochs 217 finished !\n",
      "TOTAL LOSS : 7.2927093505859375\n",
      "218 Iteration ...\n",
      "Epochs 218 finished !\n",
      "TOTAL LOSS : 7.2849650382995605\n",
      "219 Iteration ...\n",
      "Epochs 219 finished !\n",
      "TOTAL LOSS : 7.695895671844482\n",
      "220 Iteration ...\n",
      "Epochs 220 finished !\n",
      "TOTAL LOSS : 7.738719940185547\n",
      "221 Iteration ...\n",
      "Epochs 221 finished !\n",
      "TOTAL LOSS : 7.964433193206787\n",
      "222 Iteration ...\n",
      "Epochs 222 finished !\n",
      "TOTAL LOSS : 7.7350945472717285\n",
      "223 Iteration ...\n",
      "Epochs 223 finished !\n",
      "TOTAL LOSS : 7.775584697723389\n",
      "224 Iteration ...\n",
      "Epochs 224 finished !\n",
      "TOTAL LOSS : 7.879431247711182\n",
      "225 Iteration ...\n",
      "Epochs 225 finished !\n",
      "TOTAL LOSS : 7.915828227996826\n",
      "226 Iteration ...\n",
      "Epochs 226 finished !\n",
      "TOTAL LOSS : 7.762380123138428\n",
      "227 Iteration ...\n",
      "Epochs 227 finished !\n",
      "TOTAL LOSS : 7.314731121063232\n",
      "228 Iteration ...\n",
      "Epochs 228 finished !\n",
      "TOTAL LOSS : 7.327617168426514\n",
      "229 Iteration ...\n",
      "Epochs 229 finished !\n",
      "TOTAL LOSS : 7.686901092529297\n",
      "230 Iteration ...\n",
      "Epochs 230 finished !\n",
      "TOTAL LOSS : 7.426732540130615\n",
      "231 Iteration ...\n",
      "Epochs 231 finished !\n",
      "TOTAL LOSS : 7.102591037750244\n",
      "232 Iteration ...\n",
      "Epochs 232 finished !\n",
      "TOTAL LOSS : 7.694983005523682\n",
      "233 Iteration ...\n",
      "Epochs 233 finished !\n",
      "TOTAL LOSS : 7.4890642166137695\n",
      "234 Iteration ...\n",
      "Epochs 234 finished !\n",
      "TOTAL LOSS : 7.479628086090088\n",
      "235 Iteration ...\n",
      "Epochs 235 finished !\n",
      "TOTAL LOSS : 7.729935646057129\n",
      "236 Iteration ...\n",
      "Epochs 236 finished !\n",
      "TOTAL LOSS : 7.412150859832764\n",
      "237 Iteration ...\n",
      "Epochs 237 finished !\n",
      "TOTAL LOSS : 7.397764682769775\n",
      "238 Iteration ...\n",
      "Epochs 238 finished !\n",
      "TOTAL LOSS : 7.5032196044921875\n",
      "239 Iteration ...\n",
      "Epochs 239 finished !\n",
      "TOTAL LOSS : 7.850794315338135\n",
      "240 Iteration ...\n",
      "Epochs 240 finished !\n",
      "TOTAL LOSS : 7.428158760070801\n",
      "241 Iteration ...\n",
      "Epochs 241 finished !\n",
      "TOTAL LOSS : 7.278505802154541\n",
      "242 Iteration ...\n",
      "Epochs 242 finished !\n",
      "TOTAL LOSS : 7.310934543609619\n",
      "243 Iteration ...\n",
      "Epochs 243 finished !\n",
      "TOTAL LOSS : 7.468487739562988\n",
      "244 Iteration ...\n",
      "Epochs 244 finished !\n",
      "TOTAL LOSS : 7.527535915374756\n",
      "245 Iteration ...\n",
      "Epochs 245 finished !\n",
      "TOTAL LOSS : 7.75615930557251\n",
      "246 Iteration ...\n",
      "Epochs 246 finished !\n",
      "TOTAL LOSS : 7.449832439422607\n",
      "247 Iteration ...\n",
      "Epochs 247 finished !\n",
      "TOTAL LOSS : 7.506512641906738\n",
      "248 Iteration ...\n",
      "Epochs 248 finished !\n",
      "TOTAL LOSS : 7.657693386077881\n",
      "249 Iteration ...\n",
      "Epochs 249 finished !\n",
      "TOTAL LOSS : 7.49568510055542\n",
      "250 Iteration ...\n",
      "Epochs 250 finished !\n",
      "TOTAL LOSS : 7.716903209686279\n",
      "251 Iteration ...\n",
      "Epochs 251 finished !\n",
      "TOTAL LOSS : 7.570321083068848\n",
      "252 Iteration ...\n",
      "Epochs 252 finished !\n",
      "TOTAL LOSS : 7.743679046630859\n",
      "253 Iteration ...\n",
      "Epochs 253 finished !\n",
      "TOTAL LOSS : 7.52028226852417\n",
      "254 Iteration ...\n",
      "Epochs 254 finished !\n",
      "TOTAL LOSS : 7.197336673736572\n",
      "255 Iteration ...\n",
      "Epochs 255 finished !\n",
      "TOTAL LOSS : 7.519405364990234\n",
      "256 Iteration ...\n",
      "Epochs 256 finished !\n",
      "TOTAL LOSS : 7.4419755935668945\n",
      "257 Iteration ...\n",
      "Epochs 257 finished !\n",
      "TOTAL LOSS : 7.454756259918213\n",
      "258 Iteration ...\n",
      "Epochs 258 finished !\n",
      "TOTAL LOSS : 7.386467933654785\n",
      "259 Iteration ...\n",
      "Epochs 259 finished !\n",
      "TOTAL LOSS : 7.566928386688232\n",
      "260 Iteration ...\n",
      "Epochs 260 finished !\n",
      "TOTAL LOSS : 7.251739025115967\n",
      "261 Iteration ...\n",
      "Epochs 261 finished !\n",
      "TOTAL LOSS : 7.323153972625732\n",
      "262 Iteration ...\n",
      "Epochs 262 finished !\n",
      "TOTAL LOSS : 7.2537841796875\n",
      "263 Iteration ...\n",
      "Epochs 263 finished !\n",
      "TOTAL LOSS : 7.273379802703857\n",
      "264 Iteration ...\n",
      "Epochs 264 finished !\n",
      "TOTAL LOSS : 7.852407932281494\n",
      "265 Iteration ...\n",
      "Epochs 265 finished !\n",
      "TOTAL LOSS : 7.884362697601318\n",
      "266 Iteration ...\n",
      "Epochs 266 finished !\n",
      "TOTAL LOSS : 7.1849493980407715\n",
      "267 Iteration ...\n",
      "Epochs 267 finished !\n",
      "TOTAL LOSS : 7.153317928314209\n",
      "268 Iteration ...\n",
      "Epochs 268 finished !\n",
      "TOTAL LOSS : 7.4528937339782715\n",
      "269 Iteration ...\n",
      "Epochs 269 finished !\n",
      "TOTAL LOSS : 7.049275875091553\n",
      "270 Iteration ...\n",
      "Epochs 270 finished !\n",
      "TOTAL LOSS : 7.387674808502197\n",
      "271 Iteration ...\n",
      "Epochs 271 finished !\n",
      "TOTAL LOSS : 7.476410865783691\n",
      "272 Iteration ...\n",
      "Epochs 272 finished !\n",
      "TOTAL LOSS : 7.303305149078369\n",
      "273 Iteration ...\n",
      "Epochs 273 finished !\n",
      "TOTAL LOSS : 7.369378089904785\n",
      "274 Iteration ...\n",
      "Epochs 274 finished !\n",
      "TOTAL LOSS : 7.069250583648682\n",
      "275 Iteration ...\n",
      "Epochs 275 finished !\n",
      "TOTAL LOSS : 6.855278968811035\n",
      "276 Iteration ...\n",
      "Epochs 276 finished !\n",
      "TOTAL LOSS : 6.93075704574585\n",
      "277 Iteration ...\n",
      "Epochs 277 finished !\n",
      "TOTAL LOSS : 6.958433628082275\n",
      "278 Iteration ...\n",
      "Epochs 278 finished !\n",
      "TOTAL LOSS : 7.28383207321167\n",
      "279 Iteration ...\n",
      "Epochs 279 finished !\n",
      "TOTAL LOSS : 7.2956461906433105\n",
      "280 Iteration ...\n",
      "Epochs 280 finished !\n",
      "TOTAL LOSS : 7.308701992034912\n",
      "281 Iteration ...\n",
      "Epochs 281 finished !\n",
      "TOTAL LOSS : 7.2090044021606445\n",
      "282 Iteration ...\n",
      "Epochs 282 finished !\n",
      "TOTAL LOSS : 7.417163372039795\n",
      "283 Iteration ...\n",
      "Epochs 283 finished !\n",
      "TOTAL LOSS : 7.166813850402832\n",
      "284 Iteration ...\n",
      "Epochs 284 finished !\n",
      "TOTAL LOSS : 7.004707336425781\n",
      "285 Iteration ...\n",
      "Epochs 285 finished !\n",
      "TOTAL LOSS : 7.177413463592529\n",
      "286 Iteration ...\n",
      "Epochs 286 finished !\n",
      "TOTAL LOSS : 6.957802772521973\n",
      "287 Iteration ...\n",
      "Epochs 287 finished !\n",
      "TOTAL LOSS : 7.3130717277526855\n",
      "288 Iteration ...\n",
      "Epochs 288 finished !\n",
      "TOTAL LOSS : 7.177986145019531\n",
      "289 Iteration ...\n",
      "Epochs 289 finished !\n",
      "TOTAL LOSS : 7.069095134735107\n",
      "290 Iteration ...\n",
      "Epochs 290 finished !\n",
      "TOTAL LOSS : 6.909768104553223\n",
      "291 Iteration ...\n",
      "Epochs 291 finished !\n",
      "TOTAL LOSS : 6.941060543060303\n",
      "292 Iteration ...\n",
      "Epochs 292 finished !\n",
      "TOTAL LOSS : 6.91573429107666\n",
      "293 Iteration ...\n",
      "Epochs 293 finished !\n",
      "TOTAL LOSS : 7.261912822723389\n",
      "294 Iteration ...\n",
      "Epochs 294 finished !\n",
      "TOTAL LOSS : 6.957547187805176\n",
      "295 Iteration ...\n",
      "Epochs 295 finished !\n",
      "TOTAL LOSS : 6.882493019104004\n",
      "296 Iteration ...\n",
      "Epochs 296 finished !\n",
      "TOTAL LOSS : 7.084812164306641\n",
      "297 Iteration ...\n",
      "Epochs 297 finished !\n",
      "TOTAL LOSS : 6.9247145652771\n",
      "298 Iteration ...\n",
      "Epochs 298 finished !\n",
      "TOTAL LOSS : 6.783942699432373\n",
      "299 Iteration ...\n",
      "Epochs 299 finished !\n",
      "TOTAL LOSS : 7.010570049285889\n",
      "300 Iteration ...\n",
      "Epochs 300 finished !\n",
      "TOTAL LOSS : 6.826302528381348\n",
      "301 Iteration ...\n",
      "Epochs 301 finished !\n",
      "TOTAL LOSS : 7.3021111488342285\n",
      "302 Iteration ...\n",
      "Epochs 302 finished !\n",
      "TOTAL LOSS : 6.812770843505859\n",
      "303 Iteration ...\n",
      "Epochs 303 finished !\n",
      "TOTAL LOSS : 6.889071941375732\n",
      "304 Iteration ...\n",
      "Epochs 304 finished !\n",
      "TOTAL LOSS : 6.8935770988464355\n",
      "305 Iteration ...\n",
      "Epochs 305 finished !\n",
      "TOTAL LOSS : 7.147237300872803\n",
      "306 Iteration ...\n",
      "Epochs 306 finished !\n",
      "TOTAL LOSS : 6.465614318847656\n",
      "307 Iteration ...\n",
      "Epochs 307 finished !\n",
      "TOTAL LOSS : 6.66614294052124\n",
      "308 Iteration ...\n",
      "Epochs 308 finished !\n",
      "TOTAL LOSS : 6.734287261962891\n",
      "309 Iteration ...\n",
      "Epochs 309 finished !\n",
      "TOTAL LOSS : 6.574134349822998\n",
      "310 Iteration ...\n",
      "Epochs 310 finished !\n",
      "TOTAL LOSS : 6.869722843170166\n",
      "311 Iteration ...\n",
      "Epochs 311 finished !\n",
      "TOTAL LOSS : 6.829593658447266\n",
      "312 Iteration ...\n",
      "Epochs 312 finished !\n",
      "TOTAL LOSS : 6.468453884124756\n",
      "313 Iteration ...\n",
      "Epochs 313 finished !\n",
      "TOTAL LOSS : 6.5923357009887695\n",
      "314 Iteration ...\n",
      "Epochs 314 finished !\n",
      "TOTAL LOSS : 6.923637390136719\n",
      "315 Iteration ...\n",
      "Epochs 315 finished !\n",
      "TOTAL LOSS : 6.545569896697998\n",
      "316 Iteration ...\n",
      "Epochs 316 finished !\n",
      "TOTAL LOSS : 6.7289628982543945\n",
      "317 Iteration ...\n",
      "Epochs 317 finished !\n",
      "TOTAL LOSS : 6.859556674957275\n",
      "318 Iteration ...\n",
      "Epochs 318 finished !\n",
      "TOTAL LOSS : 6.587252140045166\n",
      "319 Iteration ...\n",
      "Epochs 319 finished !\n",
      "TOTAL LOSS : 6.7511820793151855\n",
      "320 Iteration ...\n",
      "Epochs 320 finished !\n",
      "TOTAL LOSS : 6.918538570404053\n",
      "321 Iteration ...\n",
      "Epochs 321 finished !\n",
      "TOTAL LOSS : 6.4095048904418945\n",
      "322 Iteration ...\n",
      "Epochs 322 finished !\n",
      "TOTAL LOSS : 6.801631927490234\n",
      "323 Iteration ...\n",
      "Epochs 323 finished !\n",
      "TOTAL LOSS : 6.309596538543701\n",
      "324 Iteration ...\n",
      "Epochs 324 finished !\n",
      "TOTAL LOSS : 6.596425533294678\n",
      "325 Iteration ...\n",
      "Epochs 325 finished !\n",
      "TOTAL LOSS : 6.808511257171631\n",
      "326 Iteration ...\n",
      "Epochs 326 finished !\n",
      "TOTAL LOSS : 6.739034175872803\n",
      "327 Iteration ...\n",
      "Epochs 327 finished !\n",
      "TOTAL LOSS : 7.172962188720703\n",
      "328 Iteration ...\n",
      "Epochs 328 finished !\n",
      "TOTAL LOSS : 6.860631465911865\n",
      "329 Iteration ...\n",
      "Epochs 329 finished !\n",
      "TOTAL LOSS : 6.580655574798584\n",
      "330 Iteration ...\n",
      "Epochs 330 finished !\n",
      "TOTAL LOSS : 6.596321105957031\n",
      "331 Iteration ...\n",
      "Epochs 331 finished !\n",
      "TOTAL LOSS : 6.7645263671875\n",
      "332 Iteration ...\n",
      "Epochs 332 finished !\n",
      "TOTAL LOSS : 6.640998840332031\n",
      "333 Iteration ...\n",
      "Epochs 333 finished !\n",
      "TOTAL LOSS : 6.5901780128479\n",
      "334 Iteration ...\n",
      "Epochs 334 finished !\n",
      "TOTAL LOSS : 6.667911052703857\n",
      "335 Iteration ...\n",
      "Epochs 335 finished !\n",
      "TOTAL LOSS : 6.400977611541748\n",
      "336 Iteration ...\n",
      "Epochs 336 finished !\n",
      "TOTAL LOSS : 6.873907566070557\n",
      "337 Iteration ...\n",
      "Epochs 337 finished !\n",
      "TOTAL LOSS : 6.489345073699951\n",
      "338 Iteration ...\n",
      "Epochs 338 finished !\n",
      "TOTAL LOSS : 6.49001932144165\n",
      "339 Iteration ...\n",
      "Epochs 339 finished !\n",
      "TOTAL LOSS : 6.55092716217041\n",
      "340 Iteration ...\n",
      "Epochs 340 finished !\n",
      "TOTAL LOSS : 6.465220928192139\n",
      "341 Iteration ...\n",
      "Epochs 341 finished !\n",
      "TOTAL LOSS : 6.750344753265381\n",
      "342 Iteration ...\n",
      "Epochs 342 finished !\n",
      "TOTAL LOSS : 6.797949314117432\n",
      "343 Iteration ...\n",
      "Epochs 343 finished !\n",
      "TOTAL LOSS : 6.578188419342041\n",
      "344 Iteration ...\n",
      "Epochs 344 finished !\n",
      "TOTAL LOSS : 7.022674083709717\n",
      "345 Iteration ...\n",
      "Epochs 345 finished !\n",
      "TOTAL LOSS : 6.467657566070557\n",
      "346 Iteration ...\n",
      "Epochs 346 finished !\n",
      "TOTAL LOSS : 6.782145023345947\n",
      "347 Iteration ...\n",
      "Epochs 347 finished !\n",
      "TOTAL LOSS : 6.500547885894775\n",
      "348 Iteration ...\n",
      "Epochs 348 finished !\n",
      "TOTAL LOSS : 6.337727069854736\n",
      "349 Iteration ...\n",
      "Epochs 349 finished !\n",
      "TOTAL LOSS : 6.75604772567749\n",
      "350 Iteration ...\n",
      "Epochs 350 finished !\n",
      "TOTAL LOSS : 6.769092082977295\n",
      "351 Iteration ...\n",
      "Epochs 351 finished !\n",
      "TOTAL LOSS : 6.761401653289795\n",
      "352 Iteration ...\n",
      "Epochs 352 finished !\n",
      "TOTAL LOSS : 6.470323085784912\n",
      "353 Iteration ...\n",
      "Epochs 353 finished !\n",
      "TOTAL LOSS : 6.6705217361450195\n",
      "354 Iteration ...\n",
      "Epochs 354 finished !\n",
      "TOTAL LOSS : 6.536288738250732\n",
      "355 Iteration ...\n",
      "Epochs 355 finished !\n",
      "TOTAL LOSS : 6.467366695404053\n",
      "356 Iteration ...\n",
      "Epochs 356 finished !\n",
      "TOTAL LOSS : 6.598818302154541\n",
      "357 Iteration ...\n",
      "Epochs 357 finished !\n",
      "TOTAL LOSS : 6.797759532928467\n",
      "358 Iteration ...\n",
      "Epochs 358 finished !\n",
      "TOTAL LOSS : 6.641730785369873\n",
      "359 Iteration ...\n",
      "Epochs 359 finished !\n",
      "TOTAL LOSS : 6.5034379959106445\n",
      "360 Iteration ...\n",
      "Epochs 360 finished !\n",
      "TOTAL LOSS : 6.782696723937988\n",
      "361 Iteration ...\n",
      "Epochs 361 finished !\n",
      "TOTAL LOSS : 6.505843639373779\n",
      "362 Iteration ...\n",
      "Epochs 362 finished !\n",
      "TOTAL LOSS : 6.454178810119629\n",
      "363 Iteration ...\n",
      "Epochs 363 finished !\n",
      "TOTAL LOSS : 6.76503324508667\n",
      "364 Iteration ...\n",
      "Epochs 364 finished !\n",
      "TOTAL LOSS : 6.676219463348389\n",
      "365 Iteration ...\n",
      "Epochs 365 finished !\n",
      "TOTAL LOSS : 6.556358337402344\n",
      "366 Iteration ...\n",
      "Epochs 366 finished !\n",
      "TOTAL LOSS : 6.6615495681762695\n",
      "367 Iteration ...\n",
      "Epochs 367 finished !\n",
      "TOTAL LOSS : 6.42125940322876\n",
      "368 Iteration ...\n",
      "Epochs 368 finished !\n",
      "TOTAL LOSS : 6.4844231605529785\n",
      "369 Iteration ...\n",
      "Epochs 369 finished !\n",
      "TOTAL LOSS : 6.647459506988525\n",
      "370 Iteration ...\n",
      "Epochs 370 finished !\n",
      "TOTAL LOSS : 6.853499889373779\n",
      "371 Iteration ...\n",
      "Epochs 371 finished !\n",
      "TOTAL LOSS : 6.6580400466918945\n",
      "372 Iteration ...\n",
      "Epochs 372 finished !\n",
      "TOTAL LOSS : 6.870123386383057\n",
      "373 Iteration ...\n",
      "Epochs 373 finished !\n",
      "TOTAL LOSS : 6.967600345611572\n",
      "374 Iteration ...\n",
      "Epochs 374 finished !\n",
      "TOTAL LOSS : 6.302735805511475\n",
      "375 Iteration ...\n",
      "Epochs 375 finished !\n",
      "TOTAL LOSS : 6.778763771057129\n",
      "376 Iteration ...\n",
      "Epochs 376 finished !\n",
      "TOTAL LOSS : 6.781863689422607\n",
      "377 Iteration ...\n",
      "Epochs 377 finished !\n",
      "TOTAL LOSS : 6.865103244781494\n",
      "378 Iteration ...\n",
      "Epochs 378 finished !\n",
      "TOTAL LOSS : 6.454456329345703\n",
      "379 Iteration ...\n",
      "Epochs 379 finished !\n",
      "TOTAL LOSS : 7.039083003997803\n",
      "380 Iteration ...\n",
      "Epochs 380 finished !\n",
      "TOTAL LOSS : 6.726495265960693\n",
      "381 Iteration ...\n",
      "Epochs 381 finished !\n",
      "TOTAL LOSS : 6.957086086273193\n",
      "382 Iteration ...\n",
      "Epochs 382 finished !\n",
      "TOTAL LOSS : 6.51104736328125\n",
      "383 Iteration ...\n",
      "Epochs 383 finished !\n",
      "TOTAL LOSS : 6.832866191864014\n",
      "384 Iteration ...\n",
      "Epochs 384 finished !\n",
      "TOTAL LOSS : 6.785163879394531\n",
      "385 Iteration ...\n",
      "Epochs 385 finished !\n",
      "TOTAL LOSS : 6.726964473724365\n",
      "386 Iteration ...\n",
      "Epochs 386 finished !\n",
      "TOTAL LOSS : 6.703333377838135\n",
      "387 Iteration ...\n",
      "Epochs 387 finished !\n",
      "TOTAL LOSS : 6.623207092285156\n",
      "388 Iteration ...\n",
      "Epochs 388 finished !\n",
      "TOTAL LOSS : 6.963710308074951\n",
      "389 Iteration ...\n",
      "Epochs 389 finished !\n",
      "TOTAL LOSS : 6.50302267074585\n",
      "390 Iteration ...\n",
      "Epochs 390 finished !\n",
      "TOTAL LOSS : 6.95412015914917\n",
      "391 Iteration ...\n",
      "Epochs 391 finished !\n",
      "TOTAL LOSS : 7.023397922515869\n",
      "392 Iteration ...\n",
      "Epochs 392 finished !\n",
      "TOTAL LOSS : 6.4663286209106445\n",
      "393 Iteration ...\n",
      "Epochs 393 finished !\n",
      "TOTAL LOSS : 6.722470283508301\n",
      "394 Iteration ...\n",
      "Epochs 394 finished !\n",
      "TOTAL LOSS : 6.762220859527588\n",
      "395 Iteration ...\n",
      "Epochs 395 finished !\n",
      "TOTAL LOSS : 6.924384593963623\n",
      "396 Iteration ...\n",
      "Epochs 396 finished !\n",
      "TOTAL LOSS : 6.893743991851807\n",
      "397 Iteration ...\n",
      "Epochs 397 finished !\n",
      "TOTAL LOSS : 6.746304512023926\n",
      "398 Iteration ...\n",
      "Epochs 398 finished !\n",
      "TOTAL LOSS : 6.935980319976807\n",
      "399 Iteration ...\n",
      "Epochs 399 finished !\n",
      "TOTAL LOSS : 6.4793524742126465\n",
      "400 Iteration ...\n",
      "Epochs 400 finished !\n",
      "TOTAL LOSS : 6.4314422607421875\n",
      "401 Iteration ...\n",
      "Epochs 401 finished !\n",
      "TOTAL LOSS : 6.645692348480225\n",
      "402 Iteration ...\n",
      "Epochs 402 finished !\n",
      "TOTAL LOSS : 6.557717323303223\n",
      "403 Iteration ...\n",
      "Epochs 403 finished !\n",
      "TOTAL LOSS : 6.754266262054443\n",
      "404 Iteration ...\n",
      "Epochs 404 finished !\n",
      "TOTAL LOSS : 6.9661126136779785\n",
      "405 Iteration ...\n",
      "Epochs 405 finished !\n",
      "TOTAL LOSS : 6.931764125823975\n",
      "406 Iteration ...\n",
      "Epochs 406 finished !\n",
      "TOTAL LOSS : 6.459176540374756\n",
      "407 Iteration ...\n",
      "Epochs 407 finished !\n",
      "TOTAL LOSS : 6.408562660217285\n",
      "408 Iteration ...\n",
      "Epochs 408 finished !\n",
      "TOTAL LOSS : 6.443853855133057\n",
      "409 Iteration ...\n",
      "Epochs 409 finished !\n",
      "TOTAL LOSS : 6.685924053192139\n",
      "410 Iteration ...\n",
      "Epochs 410 finished !\n",
      "TOTAL LOSS : 6.631847381591797\n",
      "411 Iteration ...\n",
      "Epochs 411 finished !\n",
      "TOTAL LOSS : 6.962078094482422\n",
      "412 Iteration ...\n",
      "Epochs 412 finished !\n",
      "TOTAL LOSS : 6.79656982421875\n",
      "413 Iteration ...\n",
      "Epochs 413 finished !\n",
      "TOTAL LOSS : 6.612176418304443\n",
      "414 Iteration ...\n",
      "Epochs 414 finished !\n",
      "TOTAL LOSS : 6.730584621429443\n",
      "415 Iteration ...\n",
      "Epochs 415 finished !\n",
      "TOTAL LOSS : 6.774757385253906\n",
      "416 Iteration ...\n",
      "Epochs 416 finished !\n",
      "TOTAL LOSS : 6.989226818084717\n",
      "417 Iteration ...\n",
      "Epochs 417 finished !\n",
      "TOTAL LOSS : 6.592174530029297\n",
      "418 Iteration ...\n",
      "Epochs 418 finished !\n",
      "TOTAL LOSS : 6.528684139251709\n",
      "419 Iteration ...\n",
      "Epochs 419 finished !\n",
      "TOTAL LOSS : 6.569616794586182\n",
      "420 Iteration ...\n",
      "Epochs 420 finished !\n",
      "TOTAL LOSS : 6.43145751953125\n",
      "421 Iteration ...\n",
      "Epochs 421 finished !\n",
      "TOTAL LOSS : 6.8724541664123535\n",
      "422 Iteration ...\n",
      "Epochs 422 finished !\n",
      "TOTAL LOSS : 7.014363765716553\n",
      "423 Iteration ...\n",
      "Epochs 423 finished !\n",
      "TOTAL LOSS : 6.624019145965576\n",
      "424 Iteration ...\n",
      "Epochs 424 finished !\n",
      "TOTAL LOSS : 6.606393337249756\n",
      "425 Iteration ...\n",
      "Epochs 425 finished !\n",
      "TOTAL LOSS : 6.422179698944092\n",
      "426 Iteration ...\n",
      "Epochs 426 finished !\n",
      "TOTAL LOSS : 6.8266119956970215\n",
      "427 Iteration ...\n",
      "Epochs 427 finished !\n",
      "TOTAL LOSS : 6.6414313316345215\n",
      "428 Iteration ...\n",
      "Epochs 428 finished !\n",
      "TOTAL LOSS : 6.842715740203857\n",
      "429 Iteration ...\n",
      "Epochs 429 finished !\n",
      "TOTAL LOSS : 6.4876708984375\n",
      "430 Iteration ...\n",
      "Epochs 430 finished !\n",
      "TOTAL LOSS : 6.388237953186035\n",
      "431 Iteration ...\n",
      "Epochs 431 finished !\n",
      "TOTAL LOSS : 6.744503974914551\n",
      "432 Iteration ...\n",
      "Epochs 432 finished !\n",
      "TOTAL LOSS : 6.809079647064209\n",
      "433 Iteration ...\n",
      "Epochs 433 finished !\n",
      "TOTAL LOSS : 6.417694091796875\n",
      "434 Iteration ...\n",
      "Epochs 434 finished !\n",
      "TOTAL LOSS : 6.522075176239014\n",
      "435 Iteration ...\n",
      "Epochs 435 finished !\n",
      "TOTAL LOSS : 6.836370944976807\n",
      "436 Iteration ...\n",
      "Epochs 436 finished !\n",
      "TOTAL LOSS : 6.7019877433776855\n",
      "437 Iteration ...\n",
      "Epochs 437 finished !\n",
      "TOTAL LOSS : 6.791869640350342\n",
      "438 Iteration ...\n",
      "Epochs 438 finished !\n",
      "TOTAL LOSS : 6.614284515380859\n",
      "439 Iteration ...\n",
      "Epochs 439 finished !\n",
      "TOTAL LOSS : 6.802940368652344\n",
      "440 Iteration ...\n",
      "Epochs 440 finished !\n",
      "TOTAL LOSS : 6.728847026824951\n",
      "441 Iteration ...\n",
      "Epochs 441 finished !\n",
      "TOTAL LOSS : 6.932889461517334\n",
      "442 Iteration ...\n",
      "Epochs 442 finished !\n",
      "TOTAL LOSS : 6.621490478515625\n",
      "443 Iteration ...\n",
      "Epochs 443 finished !\n",
      "TOTAL LOSS : 7.117748260498047\n",
      "444 Iteration ...\n",
      "Epochs 444 finished !\n",
      "TOTAL LOSS : 6.639625549316406\n",
      "445 Iteration ...\n",
      "Epochs 445 finished !\n",
      "TOTAL LOSS : 6.8577470779418945\n",
      "446 Iteration ...\n",
      "Epochs 446 finished !\n",
      "TOTAL LOSS : 6.657068729400635\n",
      "447 Iteration ...\n",
      "Epochs 447 finished !\n",
      "TOTAL LOSS : 6.742689609527588\n",
      "448 Iteration ...\n",
      "Epochs 448 finished !\n",
      "TOTAL LOSS : 6.696709632873535\n",
      "449 Iteration ...\n",
      "Epochs 449 finished !\n",
      "TOTAL LOSS : 6.386518955230713\n",
      "450 Iteration ...\n",
      "Epochs 450 finished !\n",
      "TOTAL LOSS : 6.586823463439941\n",
      "451 Iteration ...\n",
      "Epochs 451 finished !\n",
      "TOTAL LOSS : 6.339585304260254\n",
      "452 Iteration ...\n",
      "Epochs 452 finished !\n",
      "TOTAL LOSS : 6.435906887054443\n",
      "453 Iteration ...\n",
      "Epochs 453 finished !\n",
      "TOTAL LOSS : 6.656578063964844\n",
      "454 Iteration ...\n",
      "Epochs 454 finished !\n",
      "TOTAL LOSS : 6.5225114822387695\n",
      "455 Iteration ...\n",
      "Epochs 455 finished !\n",
      "TOTAL LOSS : 6.78122091293335\n",
      "456 Iteration ...\n",
      "Epochs 456 finished !\n",
      "TOTAL LOSS : 6.865288734436035\n",
      "457 Iteration ...\n",
      "Epochs 457 finished !\n",
      "TOTAL LOSS : 6.506206035614014\n",
      "458 Iteration ...\n",
      "Epochs 458 finished !\n",
      "TOTAL LOSS : 6.698174953460693\n",
      "459 Iteration ...\n",
      "Epochs 459 finished !\n",
      "TOTAL LOSS : 6.560667514801025\n",
      "460 Iteration ...\n",
      "Epochs 460 finished !\n",
      "TOTAL LOSS : 6.4358673095703125\n",
      "461 Iteration ...\n",
      "Epochs 461 finished !\n",
      "TOTAL LOSS : 6.6033830642700195\n",
      "462 Iteration ...\n",
      "Epochs 462 finished !\n",
      "TOTAL LOSS : 6.678003787994385\n",
      "463 Iteration ...\n",
      "Epochs 463 finished !\n",
      "TOTAL LOSS : 6.676485538482666\n",
      "464 Iteration ...\n",
      "Epochs 464 finished !\n",
      "TOTAL LOSS : 6.8910651206970215\n",
      "465 Iteration ...\n",
      "Epochs 465 finished !\n",
      "TOTAL LOSS : 6.684609413146973\n",
      "466 Iteration ...\n",
      "Epochs 466 finished !\n",
      "TOTAL LOSS : 6.505102634429932\n",
      "467 Iteration ...\n",
      "Epochs 467 finished !\n",
      "TOTAL LOSS : 6.812112331390381\n",
      "468 Iteration ...\n",
      "Epochs 468 finished !\n",
      "TOTAL LOSS : 6.626262187957764\n",
      "469 Iteration ...\n",
      "Epochs 469 finished !\n",
      "TOTAL LOSS : 6.80880880355835\n",
      "470 Iteration ...\n",
      "Epochs 470 finished !\n",
      "TOTAL LOSS : 6.895852565765381\n",
      "471 Iteration ...\n",
      "Epochs 471 finished !\n",
      "TOTAL LOSS : 6.624341011047363\n",
      "472 Iteration ...\n",
      "Epochs 472 finished !\n",
      "TOTAL LOSS : 6.662784099578857\n",
      "473 Iteration ...\n",
      "Epochs 473 finished !\n",
      "TOTAL LOSS : 6.382965087890625\n",
      "474 Iteration ...\n",
      "Epochs 474 finished !\n",
      "TOTAL LOSS : 6.803804874420166\n",
      "475 Iteration ...\n",
      "Epochs 475 finished !\n",
      "TOTAL LOSS : 6.775158882141113\n",
      "476 Iteration ...\n",
      "Epochs 476 finished !\n",
      "TOTAL LOSS : 6.932015895843506\n",
      "477 Iteration ...\n",
      "Epochs 477 finished !\n",
      "TOTAL LOSS : 6.709439277648926\n",
      "478 Iteration ...\n",
      "Epochs 478 finished !\n",
      "TOTAL LOSS : 6.852839946746826\n",
      "479 Iteration ...\n",
      "Epochs 479 finished !\n",
      "TOTAL LOSS : 6.7855963706970215\n",
      "480 Iteration ...\n",
      "Epochs 480 finished !\n",
      "TOTAL LOSS : 6.456833839416504\n",
      "481 Iteration ...\n",
      "Epochs 481 finished !\n",
      "TOTAL LOSS : 6.797038555145264\n",
      "482 Iteration ...\n",
      "Epochs 482 finished !\n",
      "TOTAL LOSS : 6.738685607910156\n",
      "483 Iteration ...\n",
      "Epochs 483 finished !\n",
      "TOTAL LOSS : 6.8488664627075195\n",
      "484 Iteration ...\n",
      "Epochs 484 finished !\n",
      "TOTAL LOSS : 6.849797248840332\n",
      "485 Iteration ...\n",
      "Epochs 485 finished !\n",
      "TOTAL LOSS : 6.929912090301514\n",
      "486 Iteration ...\n",
      "Epochs 486 finished !\n",
      "TOTAL LOSS : 6.636171817779541\n",
      "487 Iteration ...\n",
      "Epochs 487 finished !\n",
      "TOTAL LOSS : 7.0775933265686035\n",
      "488 Iteration ...\n",
      "Epochs 488 finished !\n",
      "TOTAL LOSS : 6.598621368408203\n",
      "489 Iteration ...\n",
      "Epochs 489 finished !\n",
      "TOTAL LOSS : 6.750014781951904\n",
      "490 Iteration ...\n",
      "Epochs 490 finished !\n",
      "TOTAL LOSS : 6.568715572357178\n",
      "491 Iteration ...\n",
      "Epochs 491 finished !\n",
      "TOTAL LOSS : 6.997755527496338\n",
      "492 Iteration ...\n",
      "Epochs 492 finished !\n",
      "TOTAL LOSS : 6.8452630043029785\n",
      "493 Iteration ...\n",
      "Epochs 493 finished !\n",
      "TOTAL LOSS : 6.630862712860107\n",
      "494 Iteration ...\n",
      "Epochs 494 finished !\n",
      "TOTAL LOSS : 6.767882823944092\n",
      "495 Iteration ...\n",
      "Epochs 495 finished !\n",
      "TOTAL LOSS : 6.6402435302734375\n",
      "496 Iteration ...\n",
      "Epochs 496 finished !\n",
      "TOTAL LOSS : 6.744256496429443\n",
      "497 Iteration ...\n",
      "Epochs 497 finished !\n",
      "TOTAL LOSS : 6.696521282196045\n",
      "498 Iteration ...\n",
      "Epochs 498 finished !\n",
      "TOTAL LOSS : 6.609172821044922\n",
      "499 Iteration ...\n",
      "Epochs 499 finished !\n",
      "TOTAL LOSS : 6.630065441131592\n",
      "500 Iteration ...\n",
      "Epochs 500 finished !\n",
      "TOTAL LOSS : 6.78957462310791\n",
      "501 Iteration ...\n",
      "Epochs 501 finished !\n",
      "TOTAL LOSS : 6.735507488250732\n",
      "502 Iteration ...\n",
      "Epochs 502 finished !\n",
      "TOTAL LOSS : 6.4762115478515625\n",
      "503 Iteration ...\n",
      "Epochs 503 finished !\n",
      "TOTAL LOSS : 6.658858776092529\n",
      "504 Iteration ...\n",
      "Epochs 504 finished !\n",
      "TOTAL LOSS : 6.522735118865967\n",
      "505 Iteration ...\n",
      "Epochs 505 finished !\n",
      "TOTAL LOSS : 6.900542736053467\n",
      "506 Iteration ...\n",
      "Epochs 506 finished !\n",
      "TOTAL LOSS : 6.591358184814453\n",
      "507 Iteration ...\n",
      "Epochs 507 finished !\n",
      "TOTAL LOSS : 7.109133243560791\n",
      "508 Iteration ...\n",
      "Epochs 508 finished !\n",
      "TOTAL LOSS : 6.584488868713379\n",
      "509 Iteration ...\n",
      "Epochs 509 finished !\n",
      "TOTAL LOSS : 6.735149383544922\n",
      "510 Iteration ...\n",
      "Epochs 510 finished !\n",
      "TOTAL LOSS : 6.736217021942139\n",
      "511 Iteration ...\n",
      "Epochs 511 finished !\n",
      "TOTAL LOSS : 6.991700172424316\n",
      "512 Iteration ...\n",
      "Epochs 512 finished !\n",
      "TOTAL LOSS : 6.682114601135254\n",
      "513 Iteration ...\n",
      "Epochs 513 finished !\n",
      "TOTAL LOSS : 6.739295482635498\n",
      "514 Iteration ...\n",
      "Epochs 514 finished !\n",
      "TOTAL LOSS : 6.959519386291504\n",
      "515 Iteration ...\n",
      "Epochs 515 finished !\n",
      "TOTAL LOSS : 6.741152286529541\n",
      "516 Iteration ...\n",
      "Epochs 516 finished !\n",
      "TOTAL LOSS : 6.719763278961182\n",
      "517 Iteration ...\n",
      "Epochs 517 finished !\n",
      "TOTAL LOSS : 6.946157932281494\n",
      "518 Iteration ...\n",
      "Epochs 518 finished !\n",
      "TOTAL LOSS : 6.747030735015869\n",
      "519 Iteration ...\n",
      "Epochs 519 finished !\n",
      "TOTAL LOSS : 6.902248382568359\n",
      "520 Iteration ...\n",
      "Epochs 520 finished !\n",
      "TOTAL LOSS : 6.554147243499756\n",
      "521 Iteration ...\n",
      "Epochs 521 finished !\n",
      "TOTAL LOSS : 6.7337470054626465\n",
      "522 Iteration ...\n",
      "Epochs 522 finished !\n",
      "TOTAL LOSS : 6.351556777954102\n",
      "523 Iteration ...\n",
      "Epochs 523 finished !\n",
      "TOTAL LOSS : 6.400390625\n",
      "524 Iteration ...\n",
      "Epochs 524 finished !\n",
      "TOTAL LOSS : 6.290164947509766\n",
      "525 Iteration ...\n",
      "Epochs 525 finished !\n",
      "TOTAL LOSS : 6.651034832000732\n",
      "526 Iteration ...\n",
      "Epochs 526 finished !\n",
      "TOTAL LOSS : 6.575822353363037\n",
      "527 Iteration ...\n",
      "Epochs 527 finished !\n",
      "TOTAL LOSS : 6.1649169921875\n",
      "528 Iteration ...\n",
      "Epochs 528 finished !\n",
      "TOTAL LOSS : 6.2430009841918945\n",
      "529 Iteration ...\n",
      "Epochs 529 finished !\n",
      "TOTAL LOSS : 6.709651947021484\n",
      "530 Iteration ...\n",
      "Epochs 530 finished !\n",
      "TOTAL LOSS : 6.596440315246582\n",
      "531 Iteration ...\n",
      "Epochs 531 finished !\n",
      "TOTAL LOSS : 6.785582065582275\n",
      "532 Iteration ...\n",
      "Epochs 532 finished !\n",
      "TOTAL LOSS : 6.847289562225342\n",
      "533 Iteration ...\n",
      "Epochs 533 finished !\n",
      "TOTAL LOSS : 6.6648149490356445\n",
      "534 Iteration ...\n",
      "Epochs 534 finished !\n",
      "TOTAL LOSS : 6.7655487060546875\n",
      "535 Iteration ...\n",
      "Epochs 535 finished !\n",
      "TOTAL LOSS : 6.5725998878479\n",
      "536 Iteration ...\n",
      "Epochs 536 finished !\n",
      "TOTAL LOSS : 6.637809753417969\n",
      "537 Iteration ...\n",
      "Epochs 537 finished !\n",
      "TOTAL LOSS : 6.568341255187988\n",
      "538 Iteration ...\n",
      "Epochs 538 finished !\n",
      "TOTAL LOSS : 6.851385593414307\n",
      "539 Iteration ...\n",
      "Epochs 539 finished !\n",
      "TOTAL LOSS : 6.742070198059082\n",
      "540 Iteration ...\n",
      "Epochs 540 finished !\n",
      "TOTAL LOSS : 6.758245944976807\n",
      "541 Iteration ...\n",
      "Epochs 541 finished !\n",
      "TOTAL LOSS : 6.907809734344482\n",
      "542 Iteration ...\n",
      "Epochs 542 finished !\n",
      "TOTAL LOSS : 6.959997653961182\n",
      "543 Iteration ...\n",
      "Epochs 543 finished !\n",
      "TOTAL LOSS : 6.804309844970703\n",
      "544 Iteration ...\n",
      "Epochs 544 finished !\n",
      "TOTAL LOSS : 6.920272350311279\n",
      "545 Iteration ...\n",
      "Epochs 545 finished !\n",
      "TOTAL LOSS : 6.510206699371338\n",
      "546 Iteration ...\n",
      "Epochs 546 finished !\n",
      "TOTAL LOSS : 7.127045631408691\n",
      "547 Iteration ...\n",
      "Epochs 547 finished !\n",
      "TOTAL LOSS : 6.7272868156433105\n",
      "548 Iteration ...\n",
      "Epochs 548 finished !\n",
      "TOTAL LOSS : 6.710941314697266\n",
      "549 Iteration ...\n",
      "Epochs 549 finished !\n",
      "TOTAL LOSS : 6.6136794090271\n",
      "550 Iteration ...\n",
      "Epochs 550 finished !\n",
      "TOTAL LOSS : 7.029522895812988\n",
      "551 Iteration ...\n",
      "Epochs 551 finished !\n",
      "TOTAL LOSS : 6.272421836853027\n",
      "552 Iteration ...\n",
      "Epochs 552 finished !\n",
      "TOTAL LOSS : 6.520938396453857\n",
      "553 Iteration ...\n",
      "Epochs 553 finished !\n",
      "TOTAL LOSS : 6.637369632720947\n",
      "554 Iteration ...\n",
      "Epochs 554 finished !\n",
      "TOTAL LOSS : 6.863426208496094\n",
      "555 Iteration ...\n",
      "Epochs 555 finished !\n",
      "TOTAL LOSS : 6.921680450439453\n",
      "556 Iteration ...\n",
      "Epochs 556 finished !\n",
      "TOTAL LOSS : 6.577945709228516\n",
      "557 Iteration ...\n",
      "Epochs 557 finished !\n",
      "TOTAL LOSS : 6.612351417541504\n",
      "558 Iteration ...\n",
      "Epochs 558 finished !\n",
      "TOTAL LOSS : 6.796687602996826\n",
      "559 Iteration ...\n",
      "Epochs 559 finished !\n",
      "TOTAL LOSS : 6.745841979980469\n",
      "560 Iteration ...\n",
      "Epochs 560 finished !\n",
      "TOTAL LOSS : 6.442898750305176\n",
      "561 Iteration ...\n",
      "Epochs 561 finished !\n",
      "TOTAL LOSS : 7.155737400054932\n",
      "562 Iteration ...\n",
      "Epochs 562 finished !\n",
      "TOTAL LOSS : 6.834564208984375\n",
      "563 Iteration ...\n",
      "Epochs 563 finished !\n",
      "TOTAL LOSS : 6.615032196044922\n",
      "564 Iteration ...\n",
      "Epochs 564 finished !\n",
      "TOTAL LOSS : 6.701104640960693\n",
      "565 Iteration ...\n",
      "Epochs 565 finished !\n",
      "TOTAL LOSS : 6.906114101409912\n",
      "566 Iteration ...\n",
      "Epochs 566 finished !\n",
      "TOTAL LOSS : 6.748270511627197\n",
      "567 Iteration ...\n",
      "Epochs 567 finished !\n",
      "TOTAL LOSS : 6.628725528717041\n",
      "568 Iteration ...\n",
      "Epochs 568 finished !\n",
      "TOTAL LOSS : 6.638830661773682\n",
      "569 Iteration ...\n",
      "Epochs 569 finished !\n",
      "TOTAL LOSS : 7.041305065155029\n",
      "570 Iteration ...\n",
      "Epochs 570 finished !\n",
      "TOTAL LOSS : 6.9437761306762695\n",
      "571 Iteration ...\n",
      "Epochs 571 finished !\n",
      "TOTAL LOSS : 6.43130350112915\n",
      "572 Iteration ...\n",
      "Epochs 572 finished !\n",
      "TOTAL LOSS : 6.764612674713135\n",
      "573 Iteration ...\n",
      "Epochs 573 finished !\n",
      "TOTAL LOSS : 7.098411560058594\n",
      "574 Iteration ...\n",
      "Epochs 574 finished !\n",
      "TOTAL LOSS : 7.0797953605651855\n",
      "575 Iteration ...\n",
      "Epochs 575 finished !\n",
      "TOTAL LOSS : 6.863215923309326\n",
      "576 Iteration ...\n",
      "Epochs 576 finished !\n",
      "TOTAL LOSS : 6.831157684326172\n",
      "577 Iteration ...\n",
      "Epochs 577 finished !\n",
      "TOTAL LOSS : 6.795003414154053\n",
      "578 Iteration ...\n",
      "Epochs 578 finished !\n",
      "TOTAL LOSS : 6.930181980133057\n",
      "579 Iteration ...\n",
      "Epochs 579 finished !\n",
      "TOTAL LOSS : 6.731957912445068\n",
      "580 Iteration ...\n",
      "Epochs 580 finished !\n",
      "TOTAL LOSS : 6.7057671546936035\n",
      "581 Iteration ...\n",
      "Epochs 581 finished !\n",
      "TOTAL LOSS : 6.73739767074585\n",
      "582 Iteration ...\n",
      "Epochs 582 finished !\n",
      "TOTAL LOSS : 6.735248565673828\n",
      "583 Iteration ...\n",
      "Epochs 583 finished !\n",
      "TOTAL LOSS : 6.548366069793701\n",
      "584 Iteration ...\n",
      "Epochs 584 finished !\n",
      "TOTAL LOSS : 6.57410192489624\n",
      "585 Iteration ...\n",
      "Epochs 585 finished !\n",
      "TOTAL LOSS : 6.475808620452881\n",
      "586 Iteration ...\n",
      "Epochs 586 finished !\n",
      "TOTAL LOSS : 6.641107082366943\n",
      "587 Iteration ...\n",
      "Epochs 587 finished !\n",
      "TOTAL LOSS : 6.703199863433838\n",
      "588 Iteration ...\n",
      "Epochs 588 finished !\n",
      "TOTAL LOSS : 6.5788254737854\n",
      "589 Iteration ...\n",
      "Epochs 589 finished !\n",
      "TOTAL LOSS : 6.884235382080078\n",
      "590 Iteration ...\n",
      "Epochs 590 finished !\n",
      "TOTAL LOSS : 6.740883827209473\n",
      "591 Iteration ...\n",
      "Epochs 591 finished !\n",
      "TOTAL LOSS : 6.838089942932129\n",
      "592 Iteration ...\n",
      "Epochs 592 finished !\n",
      "TOTAL LOSS : 6.748241424560547\n",
      "593 Iteration ...\n",
      "Epochs 593 finished !\n",
      "TOTAL LOSS : 6.6211771965026855\n",
      "594 Iteration ...\n",
      "Epochs 594 finished !\n",
      "TOTAL LOSS : 6.843682765960693\n",
      "595 Iteration ...\n",
      "Epochs 595 finished !\n",
      "TOTAL LOSS : 6.740858554840088\n",
      "596 Iteration ...\n",
      "Epochs 596 finished !\n",
      "TOTAL LOSS : 6.573846340179443\n",
      "597 Iteration ...\n",
      "Epochs 597 finished !\n",
      "TOTAL LOSS : 6.795941352844238\n",
      "598 Iteration ...\n",
      "Epochs 598 finished !\n",
      "TOTAL LOSS : 6.784081935882568\n",
      "599 Iteration ...\n",
      "Epochs 599 finished !\n",
      "TOTAL LOSS : 6.89291524887085\n",
      "600 Iteration ...\n",
      "Epochs 600 finished !\n",
      "TOTAL LOSS : 6.4345245361328125\n",
      "601 Iteration ...\n",
      "Epochs 601 finished !\n",
      "TOTAL LOSS : 6.609169006347656\n",
      "602 Iteration ...\n",
      "Epochs 602 finished !\n",
      "TOTAL LOSS : 6.66884708404541\n",
      "603 Iteration ...\n",
      "Epochs 603 finished !\n",
      "TOTAL LOSS : 6.860463619232178\n",
      "604 Iteration ...\n",
      "Epochs 604 finished !\n",
      "TOTAL LOSS : 6.758128643035889\n",
      "605 Iteration ...\n",
      "Epochs 605 finished !\n",
      "TOTAL LOSS : 6.4481401443481445\n",
      "606 Iteration ...\n",
      "Epochs 606 finished !\n",
      "TOTAL LOSS : 6.758912086486816\n",
      "607 Iteration ...\n",
      "Epochs 607 finished !\n",
      "TOTAL LOSS : 6.648326396942139\n",
      "608 Iteration ...\n",
      "Epochs 608 finished !\n",
      "TOTAL LOSS : 6.576837062835693\n",
      "609 Iteration ...\n",
      "Epochs 609 finished !\n",
      "TOTAL LOSS : 6.6657609939575195\n",
      "610 Iteration ...\n",
      "Epochs 610 finished !\n",
      "TOTAL LOSS : 6.667335033416748\n",
      "611 Iteration ...\n",
      "Epochs 611 finished !\n",
      "TOTAL LOSS : 6.8835577964782715\n",
      "612 Iteration ...\n",
      "Epochs 612 finished !\n",
      "TOTAL LOSS : 6.450903415679932\n",
      "613 Iteration ...\n",
      "Epochs 613 finished !\n",
      "TOTAL LOSS : 6.8436598777771\n",
      "614 Iteration ...\n",
      "Epochs 614 finished !\n",
      "TOTAL LOSS : 6.644572734832764\n",
      "615 Iteration ...\n",
      "Epochs 615 finished !\n",
      "TOTAL LOSS : 6.425006866455078\n",
      "616 Iteration ...\n",
      "Epochs 616 finished !\n",
      "TOTAL LOSS : 6.517369270324707\n",
      "617 Iteration ...\n",
      "Epochs 617 finished !\n",
      "TOTAL LOSS : 6.614954471588135\n",
      "618 Iteration ...\n",
      "Epochs 618 finished !\n",
      "TOTAL LOSS : 6.858570098876953\n",
      "619 Iteration ...\n",
      "Epochs 619 finished !\n",
      "TOTAL LOSS : 6.555912971496582\n",
      "620 Iteration ...\n",
      "Epochs 620 finished !\n",
      "TOTAL LOSS : 6.6710100173950195\n",
      "621 Iteration ...\n",
      "Epochs 621 finished !\n",
      "TOTAL LOSS : 6.745802402496338\n",
      "622 Iteration ...\n",
      "Epochs 622 finished !\n",
      "TOTAL LOSS : 6.703510284423828\n",
      "623 Iteration ...\n",
      "Epochs 623 finished !\n",
      "TOTAL LOSS : 6.83089542388916\n",
      "624 Iteration ...\n",
      "Epochs 624 finished !\n",
      "TOTAL LOSS : 6.498561859130859\n",
      "625 Iteration ...\n",
      "Epochs 625 finished !\n",
      "TOTAL LOSS : 6.67181921005249\n",
      "626 Iteration ...\n",
      "Epochs 626 finished !\n",
      "TOTAL LOSS : 6.398082256317139\n",
      "627 Iteration ...\n",
      "Epochs 627 finished !\n",
      "TOTAL LOSS : 6.701623439788818\n",
      "628 Iteration ...\n",
      "Epochs 628 finished !\n",
      "TOTAL LOSS : 6.440626621246338\n",
      "629 Iteration ...\n",
      "Epochs 629 finished !\n",
      "TOTAL LOSS : 6.72100305557251\n",
      "630 Iteration ...\n",
      "Epochs 630 finished !\n",
      "TOTAL LOSS : 6.713629245758057\n",
      "631 Iteration ...\n",
      "Epochs 631 finished !\n",
      "TOTAL LOSS : 6.563828468322754\n",
      "632 Iteration ...\n",
      "Epochs 632 finished !\n",
      "TOTAL LOSS : 7.042168617248535\n",
      "633 Iteration ...\n",
      "Epochs 633 finished !\n",
      "TOTAL LOSS : 6.7909770011901855\n",
      "634 Iteration ...\n",
      "Epochs 634 finished !\n",
      "TOTAL LOSS : 6.549436092376709\n",
      "635 Iteration ...\n",
      "Epochs 635 finished !\n",
      "TOTAL LOSS : 6.464489936828613\n",
      "636 Iteration ...\n",
      "Epochs 636 finished !\n",
      "TOTAL LOSS : 6.9866766929626465\n",
      "637 Iteration ...\n",
      "Epochs 637 finished !\n",
      "TOTAL LOSS : 6.415729522705078\n",
      "638 Iteration ...\n",
      "Epochs 638 finished !\n",
      "TOTAL LOSS : 7.136211395263672\n",
      "639 Iteration ...\n",
      "Epochs 639 finished !\n",
      "TOTAL LOSS : 6.82943058013916\n",
      "640 Iteration ...\n",
      "Epochs 640 finished !\n",
      "TOTAL LOSS : 6.657044887542725\n",
      "641 Iteration ...\n",
      "Epochs 641 finished !\n",
      "TOTAL LOSS : 6.612734317779541\n",
      "642 Iteration ...\n",
      "Epochs 642 finished !\n",
      "TOTAL LOSS : 6.536264896392822\n",
      "643 Iteration ...\n",
      "Epochs 643 finished !\n",
      "TOTAL LOSS : 6.660363674163818\n",
      "644 Iteration ...\n",
      "Epochs 644 finished !\n",
      "TOTAL LOSS : 6.532153606414795\n",
      "645 Iteration ...\n",
      "Epochs 645 finished !\n",
      "TOTAL LOSS : 6.9842529296875\n",
      "646 Iteration ...\n",
      "Epochs 646 finished !\n",
      "TOTAL LOSS : 6.869675636291504\n",
      "647 Iteration ...\n",
      "Epochs 647 finished !\n",
      "TOTAL LOSS : 6.49404764175415\n",
      "648 Iteration ...\n",
      "Epochs 648 finished !\n",
      "TOTAL LOSS : 6.644573211669922\n",
      "649 Iteration ...\n",
      "Epochs 649 finished !\n",
      "TOTAL LOSS : 7.017463684082031\n",
      "650 Iteration ...\n",
      "Epochs 650 finished !\n",
      "TOTAL LOSS : 6.950334072113037\n",
      "651 Iteration ...\n",
      "Epochs 651 finished !\n",
      "TOTAL LOSS : 6.602827548980713\n",
      "652 Iteration ...\n",
      "Epochs 652 finished !\n",
      "TOTAL LOSS : 6.874456882476807\n",
      "653 Iteration ...\n",
      "Epochs 653 finished !\n",
      "TOTAL LOSS : 6.624073028564453\n",
      "654 Iteration ...\n",
      "Epochs 654 finished !\n",
      "TOTAL LOSS : 6.5189361572265625\n",
      "655 Iteration ...\n",
      "Epochs 655 finished !\n",
      "TOTAL LOSS : 7.102410316467285\n",
      "656 Iteration ...\n",
      "Epochs 656 finished !\n",
      "TOTAL LOSS : 6.848457336425781\n",
      "657 Iteration ...\n",
      "Epochs 657 finished !\n",
      "TOTAL LOSS : 6.537323951721191\n",
      "658 Iteration ...\n",
      "Epochs 658 finished !\n",
      "TOTAL LOSS : 6.711512088775635\n",
      "659 Iteration ...\n",
      "Epochs 659 finished !\n",
      "TOTAL LOSS : 6.731198310852051\n",
      "660 Iteration ...\n",
      "Epochs 660 finished !\n",
      "TOTAL LOSS : 6.492088317871094\n",
      "661 Iteration ...\n",
      "Epochs 661 finished !\n",
      "TOTAL LOSS : 6.66754674911499\n",
      "662 Iteration ...\n",
      "Epochs 662 finished !\n",
      "TOTAL LOSS : 6.929986000061035\n",
      "663 Iteration ...\n",
      "Epochs 663 finished !\n",
      "TOTAL LOSS : 6.965396881103516\n",
      "664 Iteration ...\n",
      "Epochs 664 finished !\n",
      "TOTAL LOSS : 6.545450687408447\n",
      "665 Iteration ...\n",
      "Epochs 665 finished !\n",
      "TOTAL LOSS : 6.655181884765625\n",
      "666 Iteration ...\n",
      "Epochs 666 finished !\n",
      "TOTAL LOSS : 6.754627227783203\n",
      "667 Iteration ...\n",
      "Epochs 667 finished !\n",
      "TOTAL LOSS : 6.517496585845947\n",
      "668 Iteration ...\n",
      "Epochs 668 finished !\n",
      "TOTAL LOSS : 6.716274261474609\n",
      "669 Iteration ...\n",
      "Epochs 669 finished !\n",
      "TOTAL LOSS : 6.4320807456970215\n",
      "670 Iteration ...\n",
      "Epochs 670 finished !\n",
      "TOTAL LOSS : 6.7613205909729\n",
      "671 Iteration ...\n",
      "Epochs 671 finished !\n",
      "TOTAL LOSS : 6.606181621551514\n",
      "672 Iteration ...\n",
      "Epochs 672 finished !\n",
      "TOTAL LOSS : 6.581840515136719\n",
      "673 Iteration ...\n",
      "Epochs 673 finished !\n",
      "TOTAL LOSS : 6.444250583648682\n",
      "674 Iteration ...\n",
      "Epochs 674 finished !\n",
      "TOTAL LOSS : 6.824867248535156\n",
      "675 Iteration ...\n",
      "Epochs 675 finished !\n",
      "TOTAL LOSS : 6.821175575256348\n",
      "676 Iteration ...\n",
      "Epochs 676 finished !\n",
      "TOTAL LOSS : 6.385241508483887\n",
      "677 Iteration ...\n",
      "Epochs 677 finished !\n",
      "TOTAL LOSS : 6.657614231109619\n",
      "678 Iteration ...\n",
      "Epochs 678 finished !\n",
      "TOTAL LOSS : 6.636256694793701\n",
      "679 Iteration ...\n",
      "Epochs 679 finished !\n",
      "TOTAL LOSS : 6.8112969398498535\n",
      "680 Iteration ...\n",
      "Epochs 680 finished !\n",
      "TOTAL LOSS : 6.6894755363464355\n",
      "681 Iteration ...\n",
      "Epochs 681 finished !\n",
      "TOTAL LOSS : 7.095685005187988\n",
      "682 Iteration ...\n",
      "Epochs 682 finished !\n",
      "TOTAL LOSS : 6.803061008453369\n",
      "683 Iteration ...\n",
      "Epochs 683 finished !\n",
      "TOTAL LOSS : 6.755080699920654\n",
      "684 Iteration ...\n",
      "Epochs 684 finished !\n",
      "TOTAL LOSS : 6.625123023986816\n",
      "685 Iteration ...\n",
      "Epochs 685 finished !\n",
      "TOTAL LOSS : 6.63893985748291\n",
      "686 Iteration ...\n",
      "Epochs 686 finished !\n",
      "TOTAL LOSS : 6.718724250793457\n",
      "687 Iteration ...\n",
      "Epochs 687 finished !\n",
      "TOTAL LOSS : 6.816992282867432\n",
      "688 Iteration ...\n",
      "Epochs 688 finished !\n",
      "TOTAL LOSS : 6.817012786865234\n",
      "689 Iteration ...\n",
      "Epochs 689 finished !\n",
      "TOTAL LOSS : 6.872844219207764\n",
      "690 Iteration ...\n",
      "Epochs 690 finished !\n",
      "TOTAL LOSS : 6.310606956481934\n",
      "691 Iteration ...\n",
      "Epochs 691 finished !\n",
      "TOTAL LOSS : 6.829373359680176\n",
      "692 Iteration ...\n",
      "Epochs 692 finished !\n",
      "TOTAL LOSS : 6.558174133300781\n",
      "693 Iteration ...\n",
      "Epochs 693 finished !\n",
      "TOTAL LOSS : 6.670531749725342\n",
      "694 Iteration ...\n",
      "Epochs 694 finished !\n",
      "TOTAL LOSS : 6.9450249671936035\n",
      "695 Iteration ...\n",
      "Epochs 695 finished !\n",
      "TOTAL LOSS : 6.715933322906494\n",
      "696 Iteration ...\n",
      "Epochs 696 finished !\n",
      "TOTAL LOSS : 6.652601718902588\n",
      "697 Iteration ...\n",
      "Epochs 697 finished !\n",
      "TOTAL LOSS : 6.627791881561279\n",
      "698 Iteration ...\n",
      "Epochs 698 finished !\n",
      "TOTAL LOSS : 6.76479959487915\n",
      "699 Iteration ...\n",
      "Epochs 699 finished !\n",
      "TOTAL LOSS : 6.562699317932129\n",
      "700 Iteration ...\n",
      "Epochs 700 finished !\n",
      "TOTAL LOSS : 6.524282932281494\n",
      "701 Iteration ...\n",
      "Epochs 701 finished !\n",
      "TOTAL LOSS : 6.8806986808776855\n",
      "702 Iteration ...\n",
      "Epochs 702 finished !\n",
      "TOTAL LOSS : 6.834073543548584\n",
      "703 Iteration ...\n",
      "Epochs 703 finished !\n",
      "TOTAL LOSS : 6.610097408294678\n",
      "704 Iteration ...\n",
      "Epochs 704 finished !\n",
      "TOTAL LOSS : 6.8128204345703125\n",
      "705 Iteration ...\n",
      "Epochs 705 finished !\n",
      "TOTAL LOSS : 6.476278781890869\n",
      "706 Iteration ...\n",
      "Epochs 706 finished !\n",
      "TOTAL LOSS : 6.996979713439941\n",
      "707 Iteration ...\n",
      "Epochs 707 finished !\n",
      "TOTAL LOSS : 6.984472751617432\n",
      "708 Iteration ...\n",
      "Epochs 708 finished !\n",
      "TOTAL LOSS : 7.121140480041504\n",
      "709 Iteration ...\n",
      "Epochs 709 finished !\n",
      "TOTAL LOSS : 6.466362953186035\n",
      "710 Iteration ...\n",
      "Epochs 710 finished !\n",
      "TOTAL LOSS : 6.813107490539551\n",
      "711 Iteration ...\n",
      "Epochs 711 finished !\n",
      "TOTAL LOSS : 6.604812145233154\n",
      "712 Iteration ...\n",
      "Epochs 712 finished !\n",
      "TOTAL LOSS : 6.825374603271484\n",
      "713 Iteration ...\n",
      "Epochs 713 finished !\n",
      "TOTAL LOSS : 6.732968330383301\n",
      "714 Iteration ...\n",
      "Epochs 714 finished !\n",
      "TOTAL LOSS : 6.741184234619141\n",
      "715 Iteration ...\n",
      "Epochs 715 finished !\n",
      "TOTAL LOSS : 6.7505998611450195\n",
      "716 Iteration ...\n",
      "Epochs 716 finished !\n",
      "TOTAL LOSS : 6.698925971984863\n",
      "717 Iteration ...\n",
      "Epochs 717 finished !\n",
      "TOTAL LOSS : 6.626673221588135\n",
      "718 Iteration ...\n",
      "Epochs 718 finished !\n",
      "TOTAL LOSS : 6.9529547691345215\n",
      "719 Iteration ...\n",
      "Epochs 719 finished !\n",
      "TOTAL LOSS : 7.070233345031738\n",
      "720 Iteration ...\n",
      "Epochs 720 finished !\n",
      "TOTAL LOSS : 6.858832836151123\n",
      "721 Iteration ...\n",
      "Epochs 721 finished !\n",
      "TOTAL LOSS : 6.736937046051025\n",
      "722 Iteration ...\n",
      "Epochs 722 finished !\n",
      "TOTAL LOSS : 6.676247596740723\n",
      "723 Iteration ...\n",
      "Epochs 723 finished !\n",
      "TOTAL LOSS : 6.432211399078369\n",
      "724 Iteration ...\n",
      "Epochs 724 finished !\n",
      "TOTAL LOSS : 6.624754428863525\n",
      "725 Iteration ...\n",
      "Epochs 725 finished !\n",
      "TOTAL LOSS : 6.615116119384766\n",
      "726 Iteration ...\n",
      "Epochs 726 finished !\n",
      "TOTAL LOSS : 6.641158580780029\n",
      "727 Iteration ...\n",
      "Epochs 727 finished !\n",
      "TOTAL LOSS : 6.547492980957031\n",
      "728 Iteration ...\n",
      "Epochs 728 finished !\n",
      "TOTAL LOSS : 6.562324523925781\n",
      "729 Iteration ...\n",
      "Epochs 729 finished !\n",
      "TOTAL LOSS : 6.765350341796875\n",
      "730 Iteration ...\n",
      "Epochs 730 finished !\n",
      "TOTAL LOSS : 6.447419166564941\n",
      "731 Iteration ...\n",
      "Epochs 731 finished !\n",
      "TOTAL LOSS : 6.846380710601807\n",
      "732 Iteration ...\n",
      "Epochs 732 finished !\n",
      "TOTAL LOSS : 6.373300075531006\n",
      "733 Iteration ...\n",
      "Epochs 733 finished !\n",
      "TOTAL LOSS : 6.855105876922607\n",
      "734 Iteration ...\n",
      "Epochs 734 finished !\n",
      "TOTAL LOSS : 6.4886040687561035\n",
      "735 Iteration ...\n",
      "Epochs 735 finished !\n",
      "TOTAL LOSS : 7.050687313079834\n",
      "736 Iteration ...\n",
      "Epochs 736 finished !\n",
      "TOTAL LOSS : 6.562364101409912\n",
      "737 Iteration ...\n",
      "Epochs 737 finished !\n",
      "TOTAL LOSS : 7.221955299377441\n",
      "738 Iteration ...\n",
      "Epochs 738 finished !\n",
      "TOTAL LOSS : 6.666291236877441\n",
      "739 Iteration ...\n",
      "Epochs 739 finished !\n",
      "TOTAL LOSS : 6.672857761383057\n",
      "740 Iteration ...\n",
      "Epochs 740 finished !\n",
      "TOTAL LOSS : 6.601434230804443\n",
      "741 Iteration ...\n",
      "Epochs 741 finished !\n",
      "TOTAL LOSS : 6.564064979553223\n",
      "742 Iteration ...\n",
      "Epochs 742 finished !\n",
      "TOTAL LOSS : 6.490139961242676\n",
      "743 Iteration ...\n",
      "Epochs 743 finished !\n",
      "TOTAL LOSS : 6.7585673332214355\n",
      "744 Iteration ...\n",
      "Epochs 744 finished !\n",
      "TOTAL LOSS : 6.711583614349365\n",
      "745 Iteration ...\n",
      "Epochs 745 finished !\n",
      "TOTAL LOSS : 7.082170009613037\n",
      "746 Iteration ...\n",
      "Epochs 746 finished !\n",
      "TOTAL LOSS : 6.713338375091553\n",
      "747 Iteration ...\n",
      "Epochs 747 finished !\n",
      "TOTAL LOSS : 6.3472771644592285\n",
      "748 Iteration ...\n",
      "Epochs 748 finished !\n",
      "TOTAL LOSS : 6.442576885223389\n",
      "749 Iteration ...\n",
      "Epochs 749 finished !\n",
      "TOTAL LOSS : 6.392615795135498\n",
      "750 Iteration ...\n",
      "Epochs 750 finished !\n",
      "TOTAL LOSS : 7.073112487792969\n",
      "751 Iteration ...\n",
      "Epochs 751 finished !\n",
      "TOTAL LOSS : 6.670091152191162\n",
      "752 Iteration ...\n",
      "Epochs 752 finished !\n",
      "TOTAL LOSS : 6.832740306854248\n",
      "753 Iteration ...\n",
      "Epochs 753 finished !\n",
      "TOTAL LOSS : 6.433990001678467\n",
      "754 Iteration ...\n",
      "Epochs 754 finished !\n",
      "TOTAL LOSS : 7.025803565979004\n",
      "755 Iteration ...\n",
      "Epochs 755 finished !\n",
      "TOTAL LOSS : 6.300948143005371\n",
      "756 Iteration ...\n",
      "Epochs 756 finished !\n",
      "TOTAL LOSS : 6.713500499725342\n",
      "757 Iteration ...\n",
      "Epochs 757 finished !\n",
      "TOTAL LOSS : 6.393319606781006\n",
      "758 Iteration ...\n",
      "Epochs 758 finished !\n",
      "TOTAL LOSS : 6.484735012054443\n",
      "759 Iteration ...\n",
      "Epochs 759 finished !\n",
      "TOTAL LOSS : 6.737574100494385\n",
      "760 Iteration ...\n",
      "Epochs 760 finished !\n",
      "TOTAL LOSS : 6.691970348358154\n",
      "761 Iteration ...\n",
      "Epochs 761 finished !\n",
      "TOTAL LOSS : 6.759090423583984\n",
      "762 Iteration ...\n",
      "Epochs 762 finished !\n",
      "TOTAL LOSS : 6.942325592041016\n",
      "763 Iteration ...\n",
      "Epochs 763 finished !\n",
      "TOTAL LOSS : 6.5675883293151855\n",
      "764 Iteration ...\n",
      "Epochs 764 finished !\n",
      "TOTAL LOSS : 6.315810203552246\n",
      "765 Iteration ...\n",
      "Epochs 765 finished !\n",
      "TOTAL LOSS : 6.680410861968994\n",
      "766 Iteration ...\n",
      "Epochs 766 finished !\n",
      "TOTAL LOSS : 6.6786394119262695\n",
      "767 Iteration ...\n",
      "Epochs 767 finished !\n",
      "TOTAL LOSS : 6.784207820892334\n",
      "768 Iteration ...\n",
      "Epochs 768 finished !\n",
      "TOTAL LOSS : 6.533198833465576\n",
      "769 Iteration ...\n",
      "Epochs 769 finished !\n",
      "TOTAL LOSS : 7.167585849761963\n",
      "770 Iteration ...\n",
      "Epochs 770 finished !\n",
      "TOTAL LOSS : 6.707402229309082\n",
      "771 Iteration ...\n",
      "Epochs 771 finished !\n",
      "TOTAL LOSS : 6.699752330780029\n",
      "772 Iteration ...\n",
      "Epochs 772 finished !\n",
      "TOTAL LOSS : 6.518690586090088\n",
      "773 Iteration ...\n",
      "Epochs 773 finished !\n",
      "TOTAL LOSS : 6.802899360656738\n",
      "774 Iteration ...\n",
      "Epochs 774 finished !\n",
      "TOTAL LOSS : 6.945172309875488\n",
      "775 Iteration ...\n",
      "Epochs 775 finished !\n",
      "TOTAL LOSS : 6.8378777503967285\n",
      "776 Iteration ...\n",
      "Epochs 776 finished !\n",
      "TOTAL LOSS : 7.006446838378906\n",
      "777 Iteration ...\n",
      "Epochs 777 finished !\n",
      "TOTAL LOSS : 6.767279148101807\n",
      "778 Iteration ...\n",
      "Epochs 778 finished !\n",
      "TOTAL LOSS : 6.6585564613342285\n",
      "779 Iteration ...\n",
      "Epochs 779 finished !\n",
      "TOTAL LOSS : 6.668809413909912\n",
      "780 Iteration ...\n",
      "Epochs 780 finished !\n",
      "TOTAL LOSS : 6.602414131164551\n",
      "781 Iteration ...\n",
      "Epochs 781 finished !\n",
      "TOTAL LOSS : 6.609439373016357\n",
      "782 Iteration ...\n",
      "Epochs 782 finished !\n",
      "TOTAL LOSS : 6.549687385559082\n",
      "783 Iteration ...\n",
      "Epochs 783 finished !\n",
      "TOTAL LOSS : 6.574491024017334\n",
      "784 Iteration ...\n",
      "Epochs 784 finished !\n",
      "TOTAL LOSS : 6.587914943695068\n",
      "785 Iteration ...\n",
      "Epochs 785 finished !\n",
      "TOTAL LOSS : 7.181265354156494\n",
      "786 Iteration ...\n",
      "Epochs 786 finished !\n",
      "TOTAL LOSS : 6.601328372955322\n",
      "787 Iteration ...\n",
      "Epochs 787 finished !\n",
      "TOTAL LOSS : 6.7438225746154785\n",
      "788 Iteration ...\n",
      "Epochs 788 finished !\n",
      "TOTAL LOSS : 6.605849742889404\n",
      "789 Iteration ...\n",
      "Epochs 789 finished !\n",
      "TOTAL LOSS : 6.706432342529297\n",
      "790 Iteration ...\n",
      "Epochs 790 finished !\n",
      "TOTAL LOSS : 6.703981876373291\n",
      "791 Iteration ...\n",
      "Epochs 791 finished !\n",
      "TOTAL LOSS : 6.740453243255615\n",
      "792 Iteration ...\n",
      "Epochs 792 finished !\n",
      "TOTAL LOSS : 6.546860694885254\n",
      "793 Iteration ...\n",
      "Epochs 793 finished !\n",
      "TOTAL LOSS : 6.8057403564453125\n",
      "794 Iteration ...\n",
      "Epochs 794 finished !\n",
      "TOTAL LOSS : 6.550454616546631\n",
      "795 Iteration ...\n",
      "Epochs 795 finished !\n",
      "TOTAL LOSS : 6.86395788192749\n",
      "796 Iteration ...\n",
      "Epochs 796 finished !\n",
      "TOTAL LOSS : 6.87017822265625\n",
      "797 Iteration ...\n",
      "Epochs 797 finished !\n",
      "TOTAL LOSS : 6.498268127441406\n",
      "798 Iteration ...\n",
      "Epochs 798 finished !\n",
      "TOTAL LOSS : 6.472045421600342\n",
      "799 Iteration ...\n",
      "Epochs 799 finished !\n",
      "TOTAL LOSS : 6.5306525230407715\n",
      "800 Iteration ...\n",
      "Epochs 800 finished !\n",
      "TOTAL LOSS : 6.412847995758057\n",
      "801 Iteration ...\n",
      "Epochs 801 finished !\n",
      "TOTAL LOSS : 6.690118312835693\n",
      "802 Iteration ...\n",
      "Epochs 802 finished !\n",
      "TOTAL LOSS : 6.713237285614014\n",
      "803 Iteration ...\n",
      "Epochs 803 finished !\n",
      "TOTAL LOSS : 6.7949652671813965\n",
      "804 Iteration ...\n",
      "Epochs 804 finished !\n",
      "TOTAL LOSS : 6.587719917297363\n",
      "805 Iteration ...\n",
      "Epochs 805 finished !\n",
      "TOTAL LOSS : 6.865055084228516\n",
      "806 Iteration ...\n",
      "Epochs 806 finished !\n",
      "TOTAL LOSS : 6.635280132293701\n",
      "807 Iteration ...\n",
      "Epochs 807 finished !\n",
      "TOTAL LOSS : 6.9363112449646\n",
      "808 Iteration ...\n",
      "Epochs 808 finished !\n",
      "TOTAL LOSS : 6.5023512840271\n",
      "809 Iteration ...\n",
      "Epochs 809 finished !\n",
      "TOTAL LOSS : 6.960435390472412\n",
      "810 Iteration ...\n",
      "Epochs 810 finished !\n",
      "TOTAL LOSS : 6.7615180015563965\n",
      "811 Iteration ...\n",
      "Epochs 811 finished !\n",
      "TOTAL LOSS : 6.587077617645264\n",
      "812 Iteration ...\n",
      "Epochs 812 finished !\n",
      "TOTAL LOSS : 6.872287750244141\n",
      "813 Iteration ...\n",
      "Epochs 813 finished !\n",
      "TOTAL LOSS : 6.624891757965088\n",
      "814 Iteration ...\n",
      "Epochs 814 finished !\n",
      "TOTAL LOSS : 6.8750529289245605\n",
      "815 Iteration ...\n",
      "Epochs 815 finished !\n",
      "TOTAL LOSS : 6.875756740570068\n",
      "816 Iteration ...\n",
      "Epochs 816 finished !\n",
      "TOTAL LOSS : 6.88466739654541\n",
      "817 Iteration ...\n",
      "Epochs 817 finished !\n",
      "TOTAL LOSS : 6.855711460113525\n",
      "818 Iteration ...\n",
      "Epochs 818 finished !\n",
      "TOTAL LOSS : 6.7221360206604\n",
      "819 Iteration ...\n",
      "Epochs 819 finished !\n",
      "TOTAL LOSS : 6.639140605926514\n",
      "820 Iteration ...\n",
      "Epochs 820 finished !\n",
      "TOTAL LOSS : 6.959550380706787\n",
      "821 Iteration ...\n",
      "Epochs 821 finished !\n",
      "TOTAL LOSS : 6.28681755065918\n",
      "822 Iteration ...\n",
      "Epochs 822 finished !\n",
      "TOTAL LOSS : 6.647593975067139\n",
      "823 Iteration ...\n",
      "Epochs 823 finished !\n",
      "TOTAL LOSS : 6.845348358154297\n",
      "824 Iteration ...\n",
      "Epochs 824 finished !\n",
      "TOTAL LOSS : 6.595031261444092\n",
      "825 Iteration ...\n",
      "Epochs 825 finished !\n",
      "TOTAL LOSS : 7.0255303382873535\n",
      "826 Iteration ...\n",
      "Epochs 826 finished !\n",
      "TOTAL LOSS : 6.542725563049316\n",
      "827 Iteration ...\n",
      "Epochs 827 finished !\n",
      "TOTAL LOSS : 6.886493682861328\n",
      "828 Iteration ...\n",
      "Epochs 828 finished !\n",
      "TOTAL LOSS : 6.646650791168213\n",
      "829 Iteration ...\n",
      "Epochs 829 finished !\n",
      "TOTAL LOSS : 6.819969177246094\n",
      "830 Iteration ...\n",
      "Epochs 830 finished !\n",
      "TOTAL LOSS : 6.643695831298828\n",
      "831 Iteration ...\n",
      "Epochs 831 finished !\n",
      "TOTAL LOSS : 6.740975856781006\n",
      "832 Iteration ...\n",
      "Epochs 832 finished !\n",
      "TOTAL LOSS : 6.6979875564575195\n",
      "833 Iteration ...\n",
      "Epochs 833 finished !\n",
      "TOTAL LOSS : 6.642068386077881\n",
      "834 Iteration ...\n",
      "Epochs 834 finished !\n",
      "TOTAL LOSS : 6.508265972137451\n",
      "835 Iteration ...\n",
      "Epochs 835 finished !\n",
      "TOTAL LOSS : 6.56646203994751\n",
      "836 Iteration ...\n",
      "Epochs 836 finished !\n",
      "TOTAL LOSS : 6.72682523727417\n",
      "837 Iteration ...\n",
      "Epochs 837 finished !\n",
      "TOTAL LOSS : 6.496227264404297\n",
      "838 Iteration ...\n",
      "Epochs 838 finished !\n",
      "TOTAL LOSS : 6.264597415924072\n",
      "839 Iteration ...\n",
      "Epochs 839 finished !\n",
      "TOTAL LOSS : 6.769201755523682\n",
      "840 Iteration ...\n",
      "Epochs 840 finished !\n",
      "TOTAL LOSS : 6.693171977996826\n",
      "841 Iteration ...\n",
      "Epochs 841 finished !\n",
      "TOTAL LOSS : 6.992649078369141\n",
      "842 Iteration ...\n",
      "Epochs 842 finished !\n",
      "TOTAL LOSS : 6.5641093254089355\n",
      "843 Iteration ...\n",
      "Epochs 843 finished !\n",
      "TOTAL LOSS : 6.777513027191162\n",
      "844 Iteration ...\n",
      "Epochs 844 finished !\n",
      "TOTAL LOSS : 6.696940898895264\n",
      "845 Iteration ...\n",
      "Epochs 845 finished !\n",
      "TOTAL LOSS : 6.621009826660156\n",
      "846 Iteration ...\n",
      "Epochs 846 finished !\n",
      "TOTAL LOSS : 6.658944129943848\n",
      "847 Iteration ...\n",
      "Epochs 847 finished !\n",
      "TOTAL LOSS : 6.822036266326904\n",
      "848 Iteration ...\n",
      "Epochs 848 finished !\n",
      "TOTAL LOSS : 6.572908878326416\n",
      "849 Iteration ...\n",
      "Epochs 849 finished !\n",
      "TOTAL LOSS : 6.492768287658691\n",
      "850 Iteration ...\n",
      "Epochs 850 finished !\n",
      "TOTAL LOSS : 7.177832126617432\n",
      "851 Iteration ...\n",
      "Epochs 851 finished !\n",
      "TOTAL LOSS : 6.514620304107666\n",
      "852 Iteration ...\n",
      "Epochs 852 finished !\n",
      "TOTAL LOSS : 6.533488750457764\n",
      "853 Iteration ...\n",
      "Epochs 853 finished !\n",
      "TOTAL LOSS : 6.91045618057251\n",
      "854 Iteration ...\n",
      "Epochs 854 finished !\n",
      "TOTAL LOSS : 6.412087917327881\n",
      "855 Iteration ...\n",
      "Epochs 855 finished !\n",
      "TOTAL LOSS : 6.747145175933838\n",
      "856 Iteration ...\n",
      "Epochs 856 finished !\n",
      "TOTAL LOSS : 6.948519229888916\n",
      "857 Iteration ...\n",
      "Epochs 857 finished !\n",
      "TOTAL LOSS : 6.814183712005615\n",
      "858 Iteration ...\n",
      "Epochs 858 finished !\n",
      "TOTAL LOSS : 6.607322692871094\n",
      "859 Iteration ...\n",
      "Epochs 859 finished !\n",
      "TOTAL LOSS : 6.864698886871338\n",
      "860 Iteration ...\n",
      "Epochs 860 finished !\n",
      "TOTAL LOSS : 6.738925933837891\n",
      "861 Iteration ...\n",
      "Epochs 861 finished !\n",
      "TOTAL LOSS : 6.868075847625732\n",
      "862 Iteration ...\n",
      "Epochs 862 finished !\n",
      "TOTAL LOSS : 6.945489406585693\n",
      "863 Iteration ...\n",
      "Epochs 863 finished !\n",
      "TOTAL LOSS : 6.604577541351318\n",
      "864 Iteration ...\n",
      "Epochs 864 finished !\n",
      "TOTAL LOSS : 6.467679500579834\n",
      "865 Iteration ...\n",
      "Epochs 865 finished !\n",
      "TOTAL LOSS : 6.248286247253418\n",
      "866 Iteration ...\n",
      "Epochs 866 finished !\n",
      "TOTAL LOSS : 6.593323707580566\n",
      "867 Iteration ...\n",
      "Epochs 867 finished !\n",
      "TOTAL LOSS : 6.74633264541626\n",
      "868 Iteration ...\n",
      "Epochs 868 finished !\n",
      "TOTAL LOSS : 6.8793182373046875\n",
      "869 Iteration ...\n",
      "Epochs 869 finished !\n",
      "TOTAL LOSS : 6.634274482727051\n",
      "870 Iteration ...\n",
      "Epochs 870 finished !\n",
      "TOTAL LOSS : 6.989482879638672\n",
      "871 Iteration ...\n",
      "Epochs 871 finished !\n",
      "TOTAL LOSS : 6.530803680419922\n",
      "872 Iteration ...\n",
      "Epochs 872 finished !\n",
      "TOTAL LOSS : 6.725555419921875\n",
      "873 Iteration ...\n",
      "Epochs 873 finished !\n",
      "TOTAL LOSS : 6.815400123596191\n",
      "874 Iteration ...\n",
      "Epochs 874 finished !\n",
      "TOTAL LOSS : 6.647593021392822\n",
      "875 Iteration ...\n",
      "Epochs 875 finished !\n",
      "TOTAL LOSS : 6.9382548332214355\n",
      "876 Iteration ...\n",
      "Epochs 876 finished !\n",
      "TOTAL LOSS : 6.858304023742676\n",
      "877 Iteration ...\n",
      "Epochs 877 finished !\n",
      "TOTAL LOSS : 6.646276950836182\n",
      "878 Iteration ...\n",
      "Epochs 878 finished !\n",
      "TOTAL LOSS : 6.536096096038818\n",
      "879 Iteration ...\n",
      "Epochs 879 finished !\n",
      "TOTAL LOSS : 6.366594314575195\n",
      "880 Iteration ...\n",
      "Epochs 880 finished !\n",
      "TOTAL LOSS : 6.590933322906494\n",
      "881 Iteration ...\n",
      "Epochs 881 finished !\n",
      "TOTAL LOSS : 6.6811370849609375\n",
      "882 Iteration ...\n",
      "Epochs 882 finished !\n",
      "TOTAL LOSS : 6.625972270965576\n",
      "883 Iteration ...\n",
      "Epochs 883 finished !\n",
      "TOTAL LOSS : 6.679696559906006\n",
      "884 Iteration ...\n",
      "Epochs 884 finished !\n",
      "TOTAL LOSS : 6.540043830871582\n",
      "885 Iteration ...\n",
      "Epochs 885 finished !\n",
      "TOTAL LOSS : 6.958643436431885\n",
      "886 Iteration ...\n",
      "Epochs 886 finished !\n",
      "TOTAL LOSS : 6.638988018035889\n",
      "887 Iteration ...\n",
      "Epochs 887 finished !\n",
      "TOTAL LOSS : 6.39075231552124\n",
      "888 Iteration ...\n",
      "Epochs 888 finished !\n",
      "TOTAL LOSS : 6.71429443359375\n",
      "889 Iteration ...\n",
      "Epochs 889 finished !\n",
      "TOTAL LOSS : 6.851245403289795\n",
      "890 Iteration ...\n",
      "Epochs 890 finished !\n",
      "TOTAL LOSS : 6.862992286682129\n",
      "891 Iteration ...\n",
      "Epochs 891 finished !\n",
      "TOTAL LOSS : 6.715029239654541\n",
      "892 Iteration ...\n",
      "Epochs 892 finished !\n",
      "TOTAL LOSS : 7.0224833488464355\n",
      "893 Iteration ...\n",
      "Epochs 893 finished !\n",
      "TOTAL LOSS : 6.961269378662109\n",
      "894 Iteration ...\n",
      "Epochs 894 finished !\n",
      "TOTAL LOSS : 6.496267795562744\n",
      "895 Iteration ...\n",
      "Epochs 895 finished !\n",
      "TOTAL LOSS : 6.833653926849365\n",
      "896 Iteration ...\n",
      "Epochs 896 finished !\n",
      "TOTAL LOSS : 6.802372932434082\n",
      "897 Iteration ...\n",
      "Epochs 897 finished !\n",
      "TOTAL LOSS : 6.717853546142578\n",
      "898 Iteration ...\n",
      "Epochs 898 finished !\n",
      "TOTAL LOSS : 6.509774208068848\n",
      "899 Iteration ...\n",
      "Epochs 899 finished !\n",
      "TOTAL LOSS : 6.839150905609131\n",
      "900 Iteration ...\n",
      "Epochs 900 finished !\n",
      "TOTAL LOSS : 6.5055670738220215\n",
      "901 Iteration ...\n",
      "Epochs 901 finished !\n",
      "TOTAL LOSS : 6.6155266761779785\n",
      "902 Iteration ...\n",
      "Epochs 902 finished !\n",
      "TOTAL LOSS : 6.7712554931640625\n",
      "903 Iteration ...\n",
      "Epochs 903 finished !\n",
      "TOTAL LOSS : 6.3840861320495605\n",
      "904 Iteration ...\n",
      "Epochs 904 finished !\n",
      "TOTAL LOSS : 6.8206048011779785\n",
      "905 Iteration ...\n",
      "Epochs 905 finished !\n",
      "TOTAL LOSS : 6.704184055328369\n",
      "906 Iteration ...\n",
      "Epochs 906 finished !\n",
      "TOTAL LOSS : 6.682849407196045\n",
      "907 Iteration ...\n",
      "Epochs 907 finished !\n",
      "TOTAL LOSS : 6.6501078605651855\n",
      "908 Iteration ...\n",
      "Epochs 908 finished !\n",
      "TOTAL LOSS : 6.528018474578857\n",
      "909 Iteration ...\n",
      "Epochs 909 finished !\n",
      "TOTAL LOSS : 6.7412109375\n",
      "910 Iteration ...\n",
      "Epochs 910 finished !\n",
      "TOTAL LOSS : 6.67140531539917\n",
      "911 Iteration ...\n",
      "Epochs 911 finished !\n",
      "TOTAL LOSS : 6.7975287437438965\n",
      "912 Iteration ...\n",
      "Epochs 912 finished !\n",
      "TOTAL LOSS : 6.544435977935791\n",
      "913 Iteration ...\n",
      "Epochs 913 finished !\n",
      "TOTAL LOSS : 6.771077632904053\n",
      "914 Iteration ...\n",
      "Epochs 914 finished !\n",
      "TOTAL LOSS : 6.582974433898926\n",
      "915 Iteration ...\n",
      "Epochs 915 finished !\n",
      "TOTAL LOSS : 6.597332954406738\n",
      "916 Iteration ...\n",
      "Epochs 916 finished !\n",
      "TOTAL LOSS : 6.9507670402526855\n",
      "917 Iteration ...\n",
      "Epochs 917 finished !\n",
      "TOTAL LOSS : 6.9044036865234375\n",
      "918 Iteration ...\n",
      "Epochs 918 finished !\n",
      "TOTAL LOSS : 6.711955547332764\n",
      "919 Iteration ...\n",
      "Epochs 919 finished !\n",
      "TOTAL LOSS : 6.6935272216796875\n",
      "920 Iteration ...\n",
      "Epochs 920 finished !\n",
      "TOTAL LOSS : 6.62977933883667\n",
      "921 Iteration ...\n",
      "Epochs 921 finished !\n",
      "TOTAL LOSS : 6.646372318267822\n",
      "922 Iteration ...\n",
      "Epochs 922 finished !\n",
      "TOTAL LOSS : 6.917760372161865\n",
      "923 Iteration ...\n",
      "Epochs 923 finished !\n",
      "TOTAL LOSS : 6.899540901184082\n",
      "924 Iteration ...\n",
      "Epochs 924 finished !\n",
      "TOTAL LOSS : 6.740644931793213\n",
      "925 Iteration ...\n",
      "Epochs 925 finished !\n",
      "TOTAL LOSS : 6.589057445526123\n",
      "926 Iteration ...\n",
      "Epochs 926 finished !\n",
      "TOTAL LOSS : 6.600886821746826\n",
      "927 Iteration ...\n",
      "Epochs 927 finished !\n",
      "TOTAL LOSS : 6.47423791885376\n",
      "928 Iteration ...\n",
      "Epochs 928 finished !\n",
      "TOTAL LOSS : 6.388728141784668\n",
      "929 Iteration ...\n",
      "Epochs 929 finished !\n",
      "TOTAL LOSS : 6.71127462387085\n",
      "930 Iteration ...\n",
      "Epochs 930 finished !\n",
      "TOTAL LOSS : 6.524564266204834\n",
      "931 Iteration ...\n",
      "Epochs 931 finished !\n",
      "TOTAL LOSS : 6.4966044425964355\n",
      "932 Iteration ...\n",
      "Epochs 932 finished !\n",
      "TOTAL LOSS : 6.6389689445495605\n",
      "933 Iteration ...\n",
      "Epochs 933 finished !\n",
      "TOTAL LOSS : 6.498520851135254\n",
      "934 Iteration ...\n",
      "Epochs 934 finished !\n",
      "TOTAL LOSS : 6.77979040145874\n",
      "935 Iteration ...\n",
      "Epochs 935 finished !\n",
      "TOTAL LOSS : 6.786262512207031\n",
      "936 Iteration ...\n",
      "Epochs 936 finished !\n",
      "TOTAL LOSS : 6.839425563812256\n",
      "937 Iteration ...\n",
      "Epochs 937 finished !\n",
      "TOTAL LOSS : 6.6584062576293945\n",
      "938 Iteration ...\n",
      "Epochs 938 finished !\n",
      "TOTAL LOSS : 6.714799404144287\n",
      "939 Iteration ...\n",
      "Epochs 939 finished !\n",
      "TOTAL LOSS : 6.490184783935547\n",
      "940 Iteration ...\n",
      "Epochs 940 finished !\n",
      "TOTAL LOSS : 6.534465312957764\n",
      "941 Iteration ...\n",
      "Epochs 941 finished !\n",
      "TOTAL LOSS : 6.696463108062744\n",
      "942 Iteration ...\n",
      "Epochs 942 finished !\n",
      "TOTAL LOSS : 6.993030548095703\n",
      "943 Iteration ...\n",
      "Epochs 943 finished !\n",
      "TOTAL LOSS : 6.9505181312561035\n",
      "944 Iteration ...\n",
      "Epochs 944 finished !\n",
      "TOTAL LOSS : 6.645091533660889\n",
      "945 Iteration ...\n",
      "Epochs 945 finished !\n",
      "TOTAL LOSS : 6.959341526031494\n",
      "946 Iteration ...\n",
      "Epochs 946 finished !\n",
      "TOTAL LOSS : 6.86836576461792\n",
      "947 Iteration ...\n",
      "Epochs 947 finished !\n",
      "TOTAL LOSS : 6.449429988861084\n",
      "948 Iteration ...\n",
      "Epochs 948 finished !\n",
      "TOTAL LOSS : 6.62678861618042\n",
      "949 Iteration ...\n",
      "Epochs 949 finished !\n",
      "TOTAL LOSS : 6.9142913818359375\n",
      "950 Iteration ...\n",
      "Epochs 950 finished !\n",
      "TOTAL LOSS : 6.728675365447998\n",
      "951 Iteration ...\n",
      "Epochs 951 finished !\n",
      "TOTAL LOSS : 6.5919508934021\n",
      "952 Iteration ...\n",
      "Epochs 952 finished !\n",
      "TOTAL LOSS : 6.610756874084473\n",
      "953 Iteration ...\n",
      "Epochs 953 finished !\n",
      "TOTAL LOSS : 6.5356764793396\n",
      "954 Iteration ...\n",
      "Epochs 954 finished !\n",
      "TOTAL LOSS : 6.4354071617126465\n",
      "955 Iteration ...\n",
      "Epochs 955 finished !\n",
      "TOTAL LOSS : 6.607087135314941\n",
      "956 Iteration ...\n",
      "Epochs 956 finished !\n",
      "TOTAL LOSS : 6.798165321350098\n",
      "957 Iteration ...\n",
      "Epochs 957 finished !\n",
      "TOTAL LOSS : 6.532717227935791\n",
      "958 Iteration ...\n",
      "Epochs 958 finished !\n",
      "TOTAL LOSS : 6.4200286865234375\n",
      "959 Iteration ...\n",
      "Epochs 959 finished !\n",
      "TOTAL LOSS : 6.276229381561279\n",
      "960 Iteration ...\n",
      "Epochs 960 finished !\n",
      "TOTAL LOSS : 6.682594299316406\n",
      "961 Iteration ...\n",
      "Epochs 961 finished !\n",
      "TOTAL LOSS : 6.6904754638671875\n",
      "962 Iteration ...\n",
      "Epochs 962 finished !\n",
      "TOTAL LOSS : 6.557427883148193\n",
      "963 Iteration ...\n",
      "Epochs 963 finished !\n",
      "TOTAL LOSS : 6.702949047088623\n",
      "964 Iteration ...\n",
      "Epochs 964 finished !\n",
      "TOTAL LOSS : 6.669106960296631\n",
      "965 Iteration ...\n",
      "Epochs 965 finished !\n",
      "TOTAL LOSS : 6.937658786773682\n",
      "966 Iteration ...\n",
      "Epochs 966 finished !\n",
      "TOTAL LOSS : 6.812598705291748\n",
      "967 Iteration ...\n",
      "Epochs 967 finished !\n",
      "TOTAL LOSS : 6.53889799118042\n",
      "968 Iteration ...\n",
      "Epochs 968 finished !\n",
      "TOTAL LOSS : 6.598249912261963\n",
      "969 Iteration ...\n",
      "Epochs 969 finished !\n",
      "TOTAL LOSS : 6.481938362121582\n",
      "970 Iteration ...\n",
      "Epochs 970 finished !\n",
      "TOTAL LOSS : 6.447203159332275\n",
      "971 Iteration ...\n",
      "Epochs 971 finished !\n",
      "TOTAL LOSS : 6.304421901702881\n",
      "972 Iteration ...\n",
      "Epochs 972 finished !\n",
      "TOTAL LOSS : 6.675618648529053\n",
      "973 Iteration ...\n",
      "Epochs 973 finished !\n",
      "TOTAL LOSS : 6.988892555236816\n",
      "974 Iteration ...\n",
      "Epochs 974 finished !\n",
      "TOTAL LOSS : 6.492282390594482\n",
      "975 Iteration ...\n",
      "Epochs 975 finished !\n",
      "TOTAL LOSS : 6.769299507141113\n",
      "976 Iteration ...\n",
      "Epochs 976 finished !\n",
      "TOTAL LOSS : 6.772096157073975\n",
      "977 Iteration ...\n",
      "Epochs 977 finished !\n",
      "TOTAL LOSS : 6.901378154754639\n",
      "978 Iteration ...\n",
      "Epochs 978 finished !\n",
      "TOTAL LOSS : 6.860250949859619\n",
      "979 Iteration ...\n",
      "Epochs 979 finished !\n",
      "TOTAL LOSS : 6.611068248748779\n",
      "980 Iteration ...\n",
      "Epochs 980 finished !\n",
      "TOTAL LOSS : 6.628182888031006\n",
      "981 Iteration ...\n",
      "Epochs 981 finished !\n",
      "TOTAL LOSS : 6.799224376678467\n",
      "982 Iteration ...\n",
      "Epochs 982 finished !\n",
      "TOTAL LOSS : 6.4100542068481445\n",
      "983 Iteration ...\n",
      "Epochs 983 finished !\n",
      "TOTAL LOSS : 6.784524440765381\n",
      "984 Iteration ...\n",
      "Epochs 984 finished !\n",
      "TOTAL LOSS : 6.370021820068359\n",
      "985 Iteration ...\n",
      "Epochs 985 finished !\n",
      "TOTAL LOSS : 6.677859783172607\n",
      "986 Iteration ...\n",
      "Epochs 986 finished !\n",
      "TOTAL LOSS : 6.850612163543701\n",
      "987 Iteration ...\n",
      "Epochs 987 finished !\n",
      "TOTAL LOSS : 6.901408672332764\n",
      "988 Iteration ...\n",
      "Epochs 988 finished !\n",
      "TOTAL LOSS : 6.757134914398193\n",
      "989 Iteration ...\n",
      "Epochs 989 finished !\n",
      "TOTAL LOSS : 6.720317840576172\n",
      "990 Iteration ...\n",
      "Epochs 990 finished !\n",
      "TOTAL LOSS : 6.517458438873291\n",
      "991 Iteration ...\n",
      "Epochs 991 finished !\n",
      "TOTAL LOSS : 6.512246131896973\n",
      "992 Iteration ...\n",
      "Epochs 992 finished !\n",
      "TOTAL LOSS : 6.606828212738037\n",
      "993 Iteration ...\n",
      "Epochs 993 finished !\n",
      "TOTAL LOSS : 6.391966819763184\n",
      "994 Iteration ...\n",
      "Epochs 994 finished !\n",
      "TOTAL LOSS : 6.366436958312988\n",
      "995 Iteration ...\n",
      "Epochs 995 finished !\n",
      "TOTAL LOSS : 6.549091339111328\n",
      "996 Iteration ...\n",
      "Epochs 996 finished !\n",
      "TOTAL LOSS : 6.788419246673584\n",
      "997 Iteration ...\n",
      "Epochs 997 finished !\n",
      "TOTAL LOSS : 6.77316427230835\n",
      "998 Iteration ...\n",
      "Epochs 998 finished !\n",
      "TOTAL LOSS : 6.816074371337891\n",
      "999 Iteration ...\n",
      "Epochs 999 finished !\n",
      "TOTAL LOSS : 6.343259811401367\n",
      "1000 Iteration ...\n",
      "Epochs 1000 finished !\n",
      "TOTAL LOSS : 6.409092903137207\n"
     ]
    }
   ],
   "source": [
    "Phi_functions,optimizers = Phi_NN()\n",
    "evaluation = train_evaluate(n_iteration,0.05,Phi_functions,optimizers)\n",
    "#P[lambda_] = evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Phi_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xx = np.linspace(10, 60, 10000).astype(np.float32)\n",
    "\n",
    "plt.plot(xx, payoff_phi(N, xx), label=\"Payoff final\", color='black', linestyle='dashed')\n",
    "\n",
    "for l in range(N-2,-1,-1):\n",
    "    # Plot Continuation Functions (C_n)\n",
    "    xx_tensor = torch.tensor(xx).reshape(-1, 1).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")  \n",
    "    Cn =Phi_functions[l](xx_tensor).detach().cpu().numpy().flatten()  \n",
    "    plt.plot(xx, Cn, label=fr\"$V_{l+1}$\", alpha=0.7)\n",
    "    plt.legend()\n",
    "plt.title('The trained functions  $V_l$')\n",
    "plt.savefig('trained_functions.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.08375265389122"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_samples = generate_black_scholes_paths(N-1,2**18).T\n",
    "price,list_price = calculate_price(Phi_functions,S_samples)\n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "sample = list_price\n",
    "mean = np.mean(sample)\n",
    "var = np.var(sample, ddof=1)\n",
    "alpha = 1 - 0.9 \n",
    "quantile = stats.norm.ppf(1 - alpha/2)  # fonction quantile \n",
    "ci_size = quantile * np.sqrt(var / sample.size)\n",
    "result = { 'mean': mean, 'var': var, \n",
    "            'lower': mean - ci_size, \n",
    "            'upper': mean + ci_size }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean': 5.0913399574341085,\n",
       " 'var': 43.9177558231073,\n",
       " 'lower': 5.070049873887621,\n",
       " 'upper': 5.112630040980596}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lambda = 10\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean': 5.10148516464195,\n",
       " 'var': 43.9734188865723,\n",
       " 'lower': 5.080181593429872,\n",
       " 'upper': 5.122788735854028}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lambda = 1\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean': 5.096274536606711,\n",
       " 'var': 44.0883770027876,\n",
       " 'lower': 5.07494313699317,\n",
       " 'upper': 5.117605936220253}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lambda = 0.1\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean': 5.094644287204089,\n",
       " 'var': 43.912972822255,\n",
       " 'lower': 5.0733553630208075,\n",
       " 'upper': 5.11593321138737}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lambda = 0.01\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
